{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owwwlxcty\\Anaconda3\\envs\\notebook-6.0.2\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем тренировочные и тестовые данные\n",
    "mnist_train = pd.read_csv('fashion-mnist_train.csv')\n",
    "mnist_test = pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработка тестовых и тренировочных данных\n",
    "x_train, y_train = mnist_train.iloc[:,1:], mnist_train['label']\n",
    "x_test, y_test = mnist_test.iloc[:,1:], mnist_test['label']\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделяем из тренировочной выборки валидационную\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, random_state=10, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ #### \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owwwlxcty\\Anaconda3\\envs\\notebook-6.0.2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# создадим модель с одним слоем\n",
    "model_regression = tf.keras.models.Sequential()\n",
    "model_regression .add(tf.keras.layers.Dense(10, activation='softmax',input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем: будем минимизировать среднюю квадратичную ошибку, оптимизировать по стохастическому градиентному спуску и оценивать качетсво модели на метрике accuracy\n",
    "model_regression.compile(\n",
    "loss='mse',\n",
    "optimizer=tf.keras.optimizers.SGD(),\n",
    "metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.0908 - acc: 0.1367 - val_loss: 0.0897 - val_acc: 0.1716\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0888 - acc: 0.2233 - val_loss: 0.0878 - val_acc: 0.2742\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0870 - acc: 0.3043 - val_loss: 0.0861 - val_acc: 0.3337\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0853 - acc: 0.3452 - val_loss: 0.0844 - val_acc: 0.3615\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0836 - acc: 0.3689 - val_loss: 0.0826 - val_acc: 0.3866\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0817 - acc: 0.3933 - val_loss: 0.0807 - val_acc: 0.4165\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0798 - acc: 0.4251 - val_loss: 0.0787 - val_acc: 0.4467\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0778 - acc: 0.4562 - val_loss: 0.0767 - val_acc: 0.4746\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0757 - acc: 0.4837 - val_loss: 0.0745 - val_acc: 0.5017\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0735 - acc: 0.5076 - val_loss: 0.0723 - val_acc: 0.5188\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0713 - acc: 0.5276 - val_loss: 0.0702 - val_acc: 0.5323\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0693 - acc: 0.5433 - val_loss: 0.0682 - val_acc: 0.5468\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0674 - acc: 0.5566 - val_loss: 0.0664 - val_acc: 0.5612\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0656 - acc: 0.5704 - val_loss: 0.0647 - val_acc: 0.5754\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0639 - acc: 0.5847 - val_loss: 0.0631 - val_acc: 0.5885\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0624 - acc: 0.5984 - val_loss: 0.0616 - val_acc: 0.6036\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0609 - acc: 0.6124 - val_loss: 0.0602 - val_acc: 0.6165\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0596 - acc: 0.6244 - val_loss: 0.0589 - val_acc: 0.6279\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0584 - acc: 0.6338 - val_loss: 0.0577 - val_acc: 0.6374\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0572 - acc: 0.6412 - val_loss: 0.0566 - val_acc: 0.6437\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0561 - acc: 0.6464 - val_loss: 0.0556 - val_acc: 0.6496\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/7\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0551 - acc: 0.6508 - val_loss: 0.0546 - val_acc: 0.6528\n",
      "Epoch 2/7\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0542 - acc: 0.6542 - val_loss: 0.0537 - val_acc: 0.6553\n",
      "Epoch 3/7\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0534 - acc: 0.6571 - val_loss: 0.0529 - val_acc: 0.6573\n",
      "Epoch 4/7\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0526 - acc: 0.6592 - val_loss: 0.0521 - val_acc: 0.6590\n",
      "Epoch 5/7\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0518 - acc: 0.6611 - val_loss: 0.0514 - val_acc: 0.6617\n",
      "Epoch 6/7\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0512 - acc: 0.6635 - val_loss: 0.0508 - val_acc: 0.6633\n",
      "Epoch 7/7\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0505 - acc: 0.6660 - val_loss: 0.0501 - val_acc: 0.6641\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0499 - acc: 0.6676 - val_loss: 0.0496 - val_acc: 0.6659\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0493 - acc: 0.6699 - val_loss: 0.0490 - val_acc: 0.6683\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0488 - acc: 0.6716 - val_loss: 0.0485 - val_acc: 0.6702\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0483 - acc: 0.6739 - val_loss: 0.0480 - val_acc: 0.6731\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0478 - acc: 0.6757 - val_loss: 0.0475 - val_acc: 0.6753\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0473 - acc: 0.6781 - val_loss: 0.0471 - val_acc: 0.6782\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0469 - acc: 0.6801 - val_loss: 0.0467 - val_acc: 0.6813\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0465 - acc: 0.6824 - val_loss: 0.0462 - val_acc: 0.6840\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0461 - acc: 0.6847 - val_loss: 0.0459 - val_acc: 0.6868\n",
      "Epoch 2/9\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0457 - acc: 0.6870 - val_loss: 0.0455 - val_acc: 0.6893\n",
      "Epoch 3/9\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0453 - acc: 0.6896 - val_loss: 0.0451 - val_acc: 0.6935\n",
      "Epoch 4/9\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0450 - acc: 0.6925 - val_loss: 0.0448 - val_acc: 0.6958\n",
      "Epoch 5/9\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0446 - acc: 0.6955 - val_loss: 0.0444 - val_acc: 0.6995\n",
      "Epoch 6/9\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0443 - acc: 0.6984 - val_loss: 0.0441 - val_acc: 0.7022\n",
      "Epoch 7/9\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0440 - acc: 0.7013 - val_loss: 0.0438 - val_acc: 0.7054\n",
      "Epoch 8/9\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0437 - acc: 0.7045 - val_loss: 0.0435 - val_acc: 0.7083\n",
      "Epoch 9/9\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0434 - acc: 0.7078 - val_loss: 0.0432 - val_acc: 0.7115\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0431 - acc: 0.7105 - val_loss: 0.0429 - val_acc: 0.7135\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0428 - acc: 0.7134 - val_loss: 0.0426 - val_acc: 0.7162\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0425 - acc: 0.7161 - val_loss: 0.0424 - val_acc: 0.7183\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0422 - acc: 0.7189 - val_loss: 0.0421 - val_acc: 0.7202\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0420 - acc: 0.7218 - val_loss: 0.0418 - val_acc: 0.7234\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0417 - acc: 0.7251 - val_loss: 0.0416 - val_acc: 0.7265\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0415 - acc: 0.7275 - val_loss: 0.0414 - val_acc: 0.7285\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0412 - acc: 0.7299 - val_loss: 0.0411 - val_acc: 0.7301\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0410 - acc: 0.7322 - val_loss: 0.0409 - val_acc: 0.7323\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0408 - acc: 0.7345 - val_loss: 0.0407 - val_acc: 0.7341\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0405 - acc: 0.7367 - val_loss: 0.0404 - val_acc: 0.7351\n",
      "Epoch 2/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0403 - acc: 0.7387 - val_loss: 0.0402 - val_acc: 0.7380\n",
      "Epoch 3/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0401 - acc: 0.7410 - val_loss: 0.0400 - val_acc: 0.7398\n",
      "Epoch 4/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0399 - acc: 0.7432 - val_loss: 0.0398 - val_acc: 0.7417\n",
      "Epoch 5/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0397 - acc: 0.7446 - val_loss: 0.0396 - val_acc: 0.7437\n",
      "Epoch 6/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0395 - acc: 0.7463 - val_loss: 0.0394 - val_acc: 0.7455\n",
      "Epoch 7/11\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0393 - acc: 0.7481 - val_loss: 0.0392 - val_acc: 0.7476\n",
      "Epoch 8/11\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0391 - acc: 0.7492 - val_loss: 0.0390 - val_acc: 0.7491\n",
      "Epoch 9/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0389 - acc: 0.7511 - val_loss: 0.0389 - val_acc: 0.7510\n",
      "Epoch 10/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0388 - acc: 0.7524 - val_loss: 0.0387 - val_acc: 0.7523\n",
      "Epoch 11/11\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0386 - acc: 0.7541 - val_loss: 0.0385 - val_acc: 0.7531\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0384 - acc: 0.7551 - val_loss: 0.0383 - val_acc: 0.7546\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0382 - acc: 0.7564 - val_loss: 0.0382 - val_acc: 0.7566\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0381 - acc: 0.7579 - val_loss: 0.0380 - val_acc: 0.7578\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0379 - acc: 0.7594 - val_loss: 0.0378 - val_acc: 0.7594\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0377 - acc: 0.7604 - val_loss: 0.0377 - val_acc: 0.7595\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0376 - acc: 0.7616 - val_loss: 0.0375 - val_acc: 0.7610\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0374 - acc: 0.7630 - val_loss: 0.0374 - val_acc: 0.7621\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0373 - acc: 0.7637 - val_loss: 0.0372 - val_acc: 0.7630\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0371 - acc: 0.7652 - val_loss: 0.0371 - val_acc: 0.7648\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0370 - acc: 0.7664 - val_loss: 0.0369 - val_acc: 0.7654\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0368 - acc: 0.7677 - val_loss: 0.0368 - val_acc: 0.7664\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0367 - acc: 0.7686 - val_loss: 0.0366 - val_acc: 0.7674\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/13\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0365 - acc: 0.7699 - val_loss: 0.0365 - val_acc: 0.7686\n",
      "Epoch 2/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0364 - acc: 0.7709 - val_loss: 0.0364 - val_acc: 0.7696\n",
      "Epoch 3/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0363 - acc: 0.7717 - val_loss: 0.0362 - val_acc: 0.7714\n",
      "Epoch 4/13\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0361 - acc: 0.7727 - val_loss: 0.0361 - val_acc: 0.7721\n",
      "Epoch 5/13\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0360 - acc: 0.7737 - val_loss: 0.0360 - val_acc: 0.7732\n",
      "Epoch 6/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0359 - acc: 0.7743 - val_loss: 0.0359 - val_acc: 0.7747\n",
      "Epoch 7/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0358 - acc: 0.7752 - val_loss: 0.0357 - val_acc: 0.7746\n",
      "Epoch 8/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0356 - acc: 0.7760 - val_loss: 0.0356 - val_acc: 0.7763\n",
      "Epoch 9/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0355 - acc: 0.7769 - val_loss: 0.0355 - val_acc: 0.7767\n",
      "Epoch 10/13\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0354 - acc: 0.7781 - val_loss: 0.0354 - val_acc: 0.7774\n",
      "Epoch 11/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0353 - acc: 0.7782 - val_loss: 0.0353 - val_acc: 0.7778\n",
      "Epoch 12/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0352 - acc: 0.7793 - val_loss: 0.0352 - val_acc: 0.7796\n",
      "Epoch 13/13\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0350 - acc: 0.7803 - val_loss: 0.0350 - val_acc: 0.7802\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/14\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0349 - acc: 0.7811 - val_loss: 0.0349 - val_acc: 0.7806\n",
      "Epoch 2/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0348 - acc: 0.7817 - val_loss: 0.0348 - val_acc: 0.7809\n",
      "Epoch 3/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0347 - acc: 0.7821 - val_loss: 0.0347 - val_acc: 0.7827\n",
      "Epoch 4/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0346 - acc: 0.7829 - val_loss: 0.0346 - val_acc: 0.7840\n",
      "Epoch 5/14\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0345 - acc: 0.7836 - val_loss: 0.0345 - val_acc: 0.7844\n",
      "Epoch 6/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0344 - acc: 0.7842 - val_loss: 0.0344 - val_acc: 0.7848\n",
      "Epoch 7/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0343 - acc: 0.7849 - val_loss: 0.0343 - val_acc: 0.7855\n",
      "Epoch 8/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0342 - acc: 0.7855 - val_loss: 0.0342 - val_acc: 0.7859\n",
      "Epoch 9/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0341 - acc: 0.7862 - val_loss: 0.0341 - val_acc: 0.7858\n",
      "Epoch 10/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0340 - acc: 0.7866 - val_loss: 0.0340 - val_acc: 0.7863\n",
      "Epoch 11/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0339 - acc: 0.7870 - val_loss: 0.0339 - val_acc: 0.7868\n",
      "Epoch 12/14\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0338 - acc: 0.7879 - val_loss: 0.0338 - val_acc: 0.7872\n",
      "Epoch 13/14\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0337 - acc: 0.7883 - val_loss: 0.0338 - val_acc: 0.7882\n",
      "Epoch 14/14\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0336 - acc: 0.7892 - val_loss: 0.0337 - val_acc: 0.7882\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0336 - acc: 0.7897 - val_loss: 0.0336 - val_acc: 0.7892\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0335 - acc: 0.7901 - val_loss: 0.0335 - val_acc: 0.7895\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0334 - acc: 0.7909 - val_loss: 0.0334 - val_acc: 0.7903\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0333 - acc: 0.7914 - val_loss: 0.0333 - val_acc: 0.7907\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0332 - acc: 0.7918 - val_loss: 0.0332 - val_acc: 0.7913\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0331 - acc: 0.7923 - val_loss: 0.0332 - val_acc: 0.7916\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0331 - acc: 0.7926 - val_loss: 0.0331 - val_acc: 0.7926\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0330 - acc: 0.7931 - val_loss: 0.0330 - val_acc: 0.7925\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0329 - acc: 0.7937 - val_loss: 0.0329 - val_acc: 0.7926\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0328 - acc: 0.7941 - val_loss: 0.0328 - val_acc: 0.7930\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0327 - acc: 0.7945 - val_loss: 0.0328 - val_acc: 0.7937\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0327 - acc: 0.7948 - val_loss: 0.0327 - val_acc: 0.7942\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0326 - acc: 0.7954 - val_loss: 0.0326 - val_acc: 0.7944\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0325 - acc: 0.7959 - val_loss: 0.0326 - val_acc: 0.7950\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0324 - acc: 0.7961 - val_loss: 0.0325 - val_acc: 0.7954\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0324 - acc: 0.7969 - val_loss: 0.0324 - val_acc: 0.7960\n",
      "Epoch 2/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0323 - acc: 0.7969 - val_loss: 0.0323 - val_acc: 0.7968\n",
      "Epoch 3/16\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0322 - acc: 0.7976 - val_loss: 0.0323 - val_acc: 0.7972\n",
      "Epoch 4/16\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0322 - acc: 0.7981 - val_loss: 0.0322 - val_acc: 0.7975\n",
      "Epoch 5/16\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0321 - acc: 0.7985 - val_loss: 0.0321 - val_acc: 0.7979\n",
      "Epoch 6/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0320 - acc: 0.7989 - val_loss: 0.0321 - val_acc: 0.7983\n",
      "Epoch 7/16\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0320 - acc: 0.7990 - val_loss: 0.0320 - val_acc: 0.7994\n",
      "Epoch 8/16\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0319 - acc: 0.7998 - val_loss: 0.0319 - val_acc: 0.7997\n",
      "Epoch 9/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0318 - acc: 0.7998 - val_loss: 0.0319 - val_acc: 0.8004\n",
      "Epoch 10/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0318 - acc: 0.8006 - val_loss: 0.0318 - val_acc: 0.8011\n",
      "Epoch 11/16\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0317 - acc: 0.8009 - val_loss: 0.0318 - val_acc: 0.8015\n",
      "Epoch 12/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0316 - acc: 0.8014 - val_loss: 0.0317 - val_acc: 0.8019\n",
      "Epoch 13/16\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0316 - acc: 0.8019 - val_loss: 0.0316 - val_acc: 0.8016\n",
      "Epoch 14/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0315 - acc: 0.8019 - val_loss: 0.0316 - val_acc: 0.8022\n",
      "Epoch 15/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0315 - acc: 0.8026 - val_loss: 0.0315 - val_acc: 0.8031\n",
      "Epoch 16/16\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0314 - acc: 0.8028 - val_loss: 0.0315 - val_acc: 0.8031\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0313 - acc: 0.8033 - val_loss: 0.0314 - val_acc: 0.8035\n",
      "Epoch 2/17\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0313 - acc: 0.8036 - val_loss: 0.0313 - val_acc: 0.8041\n",
      "Epoch 3/17\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0312 - acc: 0.8040 - val_loss: 0.0313 - val_acc: 0.8041\n",
      "Epoch 4/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0312 - acc: 0.8045 - val_loss: 0.0312 - val_acc: 0.8042\n",
      "Epoch 5/17\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0311 - acc: 0.8048 - val_loss: 0.0312 - val_acc: 0.8048\n",
      "Epoch 6/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0311 - acc: 0.8051 - val_loss: 0.0311 - val_acc: 0.8050\n",
      "Epoch 7/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0310 - acc: 0.8054 - val_loss: 0.0311 - val_acc: 0.8049\n",
      "Epoch 8/17\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0309 - acc: 0.8056 - val_loss: 0.0310 - val_acc: 0.8046\n",
      "Epoch 9/17\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0309 - acc: 0.8058 - val_loss: 0.0310 - val_acc: 0.8059\n",
      "Epoch 10/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0308 - acc: 0.8061 - val_loss: 0.0309 - val_acc: 0.8062\n",
      "Epoch 11/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0308 - acc: 0.8063 - val_loss: 0.0309 - val_acc: 0.8062\n",
      "Epoch 12/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0307 - acc: 0.8066 - val_loss: 0.0308 - val_acc: 0.8063\n",
      "Epoch 13/17\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0307 - acc: 0.8067 - val_loss: 0.0308 - val_acc: 0.8059\n",
      "Epoch 14/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0306 - acc: 0.8068 - val_loss: 0.0307 - val_acc: 0.8066\n",
      "Epoch 15/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0306 - acc: 0.8070 - val_loss: 0.0307 - val_acc: 0.8075\n",
      "Epoch 16/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0305 - acc: 0.8073 - val_loss: 0.0306 - val_acc: 0.8072\n",
      "Epoch 17/17\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0305 - acc: 0.8075 - val_loss: 0.0306 - val_acc: 0.8080\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/18\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0304 - acc: 0.8079 - val_loss: 0.0305 - val_acc: 0.8084\n",
      "Epoch 2/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0304 - acc: 0.8082 - val_loss: 0.0305 - val_acc: 0.8087\n",
      "Epoch 3/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0303 - acc: 0.8083 - val_loss: 0.0304 - val_acc: 0.8088\n",
      "Epoch 4/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0303 - acc: 0.8087 - val_loss: 0.0304 - val_acc: 0.8088\n",
      "Epoch 5/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0302 - acc: 0.8091 - val_loss: 0.0303 - val_acc: 0.8090\n",
      "Epoch 6/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0302 - acc: 0.8091 - val_loss: 0.0303 - val_acc: 0.8093\n",
      "Epoch 7/18\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0301 - acc: 0.8094 - val_loss: 0.0302 - val_acc: 0.8099\n",
      "Epoch 8/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0301 - acc: 0.8098 - val_loss: 0.0302 - val_acc: 0.8100\n",
      "Epoch 9/18\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0301 - acc: 0.8098 - val_loss: 0.0302 - val_acc: 0.8102\n",
      "Epoch 10/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0300 - acc: 0.8100 - val_loss: 0.0301 - val_acc: 0.8101\n",
      "Epoch 11/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0300 - acc: 0.8103 - val_loss: 0.0301 - val_acc: 0.8104\n",
      "Epoch 12/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0299 - acc: 0.8105 - val_loss: 0.0300 - val_acc: 0.8104\n",
      "Epoch 13/18\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0299 - acc: 0.8108 - val_loss: 0.0300 - val_acc: 0.8101\n",
      "Epoch 14/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0298 - acc: 0.8110 - val_loss: 0.0299 - val_acc: 0.8109\n",
      "Epoch 15/18\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0298 - acc: 0.8112 - val_loss: 0.0299 - val_acc: 0.8103\n",
      "Epoch 16/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0298 - acc: 0.8113 - val_loss: 0.0299 - val_acc: 0.8107\n",
      "Epoch 17/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0297 - acc: 0.8116 - val_loss: 0.0298 - val_acc: 0.8105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/18\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0297 - acc: 0.8119 - val_loss: 0.0298 - val_acc: 0.8118\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0296 - acc: 0.8123 - val_loss: 0.0297 - val_acc: 0.8118\n",
      "Epoch 2/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0296 - acc: 0.8124 - val_loss: 0.0297 - val_acc: 0.8119\n",
      "Epoch 3/19\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0295 - acc: 0.8129 - val_loss: 0.0297 - val_acc: 0.8115\n",
      "Epoch 4/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0295 - acc: 0.8129 - val_loss: 0.0296 - val_acc: 0.8121\n",
      "Epoch 5/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0295 - acc: 0.8130 - val_loss: 0.0296 - val_acc: 0.8120\n",
      "Epoch 6/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0294 - acc: 0.8132 - val_loss: 0.0295 - val_acc: 0.8123\n",
      "Epoch 7/19\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0294 - acc: 0.8134 - val_loss: 0.0295 - val_acc: 0.8128\n",
      "Epoch 8/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0294 - acc: 0.8137 - val_loss: 0.0295 - val_acc: 0.8132\n",
      "Epoch 9/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0293 - acc: 0.8137 - val_loss: 0.0294 - val_acc: 0.8130\n",
      "Epoch 10/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0293 - acc: 0.8138 - val_loss: 0.0294 - val_acc: 0.8135\n",
      "Epoch 11/19\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0292 - acc: 0.8141 - val_loss: 0.0294 - val_acc: 0.8134\n",
      "Epoch 12/19\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0292 - acc: 0.8143 - val_loss: 0.0293 - val_acc: 0.8138\n",
      "Epoch 13/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0292 - acc: 0.8145 - val_loss: 0.0293 - val_acc: 0.8138\n",
      "Epoch 14/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0291 - acc: 0.8146 - val_loss: 0.0292 - val_acc: 0.8139\n",
      "Epoch 15/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0291 - acc: 0.8148 - val_loss: 0.0292 - val_acc: 0.8139\n",
      "Epoch 16/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0291 - acc: 0.8151 - val_loss: 0.0292 - val_acc: 0.8144\n",
      "Epoch 17/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0290 - acc: 0.8152 - val_loss: 0.0291 - val_acc: 0.8147\n",
      "Epoch 18/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0290 - acc: 0.8156 - val_loss: 0.0291 - val_acc: 0.8142\n",
      "Epoch 19/19\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0290 - acc: 0.8156 - val_loss: 0.0291 - val_acc: 0.8146\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0289 - acc: 0.8158 - val_loss: 0.0290 - val_acc: 0.8150\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0289 - acc: 0.8163 - val_loss: 0.0290 - val_acc: 0.8152\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0288 - acc: 0.8163 - val_loss: 0.0290 - val_acc: 0.8150\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0288 - acc: 0.8164 - val_loss: 0.0289 - val_acc: 0.8153\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0288 - acc: 0.8167 - val_loss: 0.0289 - val_acc: 0.8156\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0287 - acc: 0.8169 - val_loss: 0.0289 - val_acc: 0.8158\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0287 - acc: 0.8169 - val_loss: 0.0288 - val_acc: 0.8160\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0287 - acc: 0.8173 - val_loss: 0.0288 - val_acc: 0.8162\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0286 - acc: 0.8176 - val_loss: 0.0288 - val_acc: 0.8166\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0286 - acc: 0.8176 - val_loss: 0.0287 - val_acc: 0.8167\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0286 - acc: 0.8178 - val_loss: 0.0287 - val_acc: 0.8170\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0286 - acc: 0.8177 - val_loss: 0.0287 - val_acc: 0.8174\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0285 - acc: 0.8180 - val_loss: 0.0286 - val_acc: 0.8174\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0285 - acc: 0.8181 - val_loss: 0.0286 - val_acc: 0.8174\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0285 - acc: 0.8185 - val_loss: 0.0286 - val_acc: 0.8174\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0284 - acc: 0.8184 - val_loss: 0.0285 - val_acc: 0.8181\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0284 - acc: 0.8187 - val_loss: 0.0285 - val_acc: 0.8179\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0284 - acc: 0.8189 - val_loss: 0.0285 - val_acc: 0.8183\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0283 - acc: 0.8191 - val_loss: 0.0285 - val_acc: 0.8185\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0283 - acc: 0.8192 - val_loss: 0.0284 - val_acc: 0.8190\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0283 - acc: 0.8193 - val_loss: 0.0284 - val_acc: 0.8191\n",
      "Epoch 2/21\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0282 - acc: 0.8193 - val_loss: 0.0284 - val_acc: 0.8191\n",
      "Epoch 3/21\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0282 - acc: 0.8192 - val_loss: 0.0283 - val_acc: 0.8184\n",
      "Epoch 4/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0282 - acc: 0.8197 - val_loss: 0.0283 - val_acc: 0.8191\n",
      "Epoch 5/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0282 - acc: 0.8197 - val_loss: 0.0283 - val_acc: 0.8197\n",
      "Epoch 6/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0281 - acc: 0.8201 - val_loss: 0.0283 - val_acc: 0.8194\n",
      "Epoch 7/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0281 - acc: 0.8201 - val_loss: 0.0282 - val_acc: 0.8196\n",
      "Epoch 8/21\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0281 - acc: 0.8202 - val_loss: 0.0282 - val_acc: 0.8199\n",
      "Epoch 9/21\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0280 - acc: 0.8205 - val_loss: 0.0282 - val_acc: 0.8200\n",
      "Epoch 10/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0280 - acc: 0.8205 - val_loss: 0.0281 - val_acc: 0.8203\n",
      "Epoch 11/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0280 - acc: 0.8208 - val_loss: 0.0281 - val_acc: 0.8207\n",
      "Epoch 12/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0280 - acc: 0.8209 - val_loss: 0.0281 - val_acc: 0.8210\n",
      "Epoch 13/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0279 - acc: 0.8208 - val_loss: 0.0281 - val_acc: 0.8205\n",
      "Epoch 14/21\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0279 - acc: 0.8210 - val_loss: 0.0280 - val_acc: 0.8207\n",
      "Epoch 15/21\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0279 - acc: 0.8208 - val_loss: 0.0280 - val_acc: 0.8207\n",
      "Epoch 16/21\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0278 - acc: 0.8211 - val_loss: 0.0280 - val_acc: 0.8213\n",
      "Epoch 17/21\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0278 - acc: 0.8214 - val_loss: 0.0280 - val_acc: 0.8214\n",
      "Epoch 18/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0278 - acc: 0.8216 - val_loss: 0.0279 - val_acc: 0.8214\n",
      "Epoch 19/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0278 - acc: 0.8215 - val_loss: 0.0279 - val_acc: 0.8213\n",
      "Epoch 20/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0277 - acc: 0.8217 - val_loss: 0.0279 - val_acc: 0.8216\n",
      "Epoch 21/21\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0277 - acc: 0.8217 - val_loss: 0.0279 - val_acc: 0.8215\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0277 - acc: 0.8220 - val_loss: 0.0278 - val_acc: 0.8216\n",
      "Epoch 2/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0277 - acc: 0.8222 - val_loss: 0.0278 - val_acc: 0.8216\n",
      "Epoch 3/22\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0276 - acc: 0.8224 - val_loss: 0.0278 - val_acc: 0.8220\n",
      "Epoch 4/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0276 - acc: 0.8225 - val_loss: 0.0277 - val_acc: 0.8222\n",
      "Epoch 5/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0276 - acc: 0.8226 - val_loss: 0.0277 - val_acc: 0.8219\n",
      "Epoch 6/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0276 - acc: 0.8226 - val_loss: 0.0277 - val_acc: 0.8218\n",
      "Epoch 7/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0275 - acc: 0.8226 - val_loss: 0.0277 - val_acc: 0.8226\n",
      "Epoch 8/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0275 - acc: 0.8228 - val_loss: 0.0277 - val_acc: 0.8227\n",
      "Epoch 9/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0275 - acc: 0.8231 - val_loss: 0.0276 - val_acc: 0.8227\n",
      "Epoch 10/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0275 - acc: 0.8230 - val_loss: 0.0276 - val_acc: 0.8229\n",
      "Epoch 11/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0274 - acc: 0.8234 - val_loss: 0.0276 - val_acc: 0.8230\n",
      "Epoch 12/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0274 - acc: 0.8232 - val_loss: 0.0276 - val_acc: 0.8235\n",
      "Epoch 13/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0274 - acc: 0.8234 - val_loss: 0.0275 - val_acc: 0.8239\n",
      "Epoch 14/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0274 - acc: 0.8239 - val_loss: 0.0275 - val_acc: 0.8235\n",
      "Epoch 15/22\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0273 - acc: 0.8240 - val_loss: 0.0275 - val_acc: 0.8234\n",
      "Epoch 16/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0273 - acc: 0.8240 - val_loss: 0.0275 - val_acc: 0.8236\n",
      "Epoch 17/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0273 - acc: 0.8241 - val_loss: 0.0274 - val_acc: 0.8240\n",
      "Epoch 18/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0273 - acc: 0.8242 - val_loss: 0.0274 - val_acc: 0.82420.0273 - acc: 0\n",
      "Epoch 19/22\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0273 - acc: 0.8242 - val_loss: 0.0274 - val_acc: 0.8243\n",
      "Epoch 20/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0272 - acc: 0.8244 - val_loss: 0.0274 - val_acc: 0.8244\n",
      "Epoch 21/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0272 - acc: 0.8245 - val_loss: 0.0273 - val_acc: 0.8245\n",
      "Epoch 22/22\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0272 - acc: 0.8248 - val_loss: 0.0273 - val_acc: 0.8247\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0272 - acc: 0.8249 - val_loss: 0.0273 - val_acc: 0.8250\n",
      "Epoch 2/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0271 - acc: 0.8250 - val_loss: 0.0273 - val_acc: 0.8248\n",
      "Epoch 3/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0271 - acc: 0.8251 - val_loss: 0.0273 - val_acc: 0.8246\n",
      "Epoch 4/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0271 - acc: 0.8253 - val_loss: 0.0272 - val_acc: 0.8253\n",
      "Epoch 5/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0271 - acc: 0.8256 - val_loss: 0.0272 - val_acc: 0.8252\n",
      "Epoch 6/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0270 - acc: 0.8254 - val_loss: 0.0272 - val_acc: 0.8256\n",
      "Epoch 7/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0270 - acc: 0.8256 - val_loss: 0.0272 - val_acc: 0.8253\n",
      "Epoch 8/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0270 - acc: 0.8259 - val_loss: 0.0272 - val_acc: 0.8256\n",
      "Epoch 9/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0270 - acc: 0.8256 - val_loss: 0.0271 - val_acc: 0.8254\n",
      "Epoch 10/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0270 - acc: 0.8256 - val_loss: 0.0271 - val_acc: 0.8255\n",
      "Epoch 11/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0269 - acc: 0.8259 - val_loss: 0.0271 - val_acc: 0.8256\n",
      "Epoch 12/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0269 - acc: 0.8260 - val_loss: 0.0271 - val_acc: 0.8263\n",
      "Epoch 13/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0269 - acc: 0.8263 - val_loss: 0.0270 - val_acc: 0.8266\n",
      "Epoch 14/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0269 - acc: 0.8263 - val_loss: 0.0270 - val_acc: 0.8263\n",
      "Epoch 15/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0269 - acc: 0.8264 - val_loss: 0.0270 - val_acc: 0.8262\n",
      "Epoch 16/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0268 - acc: 0.8264 - val_loss: 0.0270 - val_acc: 0.8265\n",
      "Epoch 17/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0268 - acc: 0.8266 - val_loss: 0.0270 - val_acc: 0.8265\n",
      "Epoch 18/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0268 - acc: 0.8267 - val_loss: 0.0269 - val_acc: 0.8270\n",
      "Epoch 19/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0268 - acc: 0.8268 - val_loss: 0.0269 - val_acc: 0.8264\n",
      "Epoch 20/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0268 - acc: 0.8269 - val_loss: 0.0269 - val_acc: 0.8270\n",
      "Epoch 21/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0267 - acc: 0.8269 - val_loss: 0.0269 - val_acc: 0.8272\n",
      "Epoch 22/23\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0267 - acc: 0.8272 - val_loss: 0.0269 - val_acc: 0.8267\n",
      "Epoch 23/23\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0267 - acc: 0.8270 - val_loss: 0.0268 - val_acc: 0.8268\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/24\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0267 - acc: 0.8272 - val_loss: 0.0268 - val_acc: 0.8272\n",
      "Epoch 2/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0267 - acc: 0.8277 - val_loss: 0.0268 - val_acc: 0.8275\n",
      "Epoch 3/24\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0266 - acc: 0.8275 - val_loss: 0.0268 - val_acc: 0.8270\n",
      "Epoch 4/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0266 - acc: 0.8278 - val_loss: 0.0268 - val_acc: 0.8273\n",
      "Epoch 5/24\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0266 - acc: 0.8281 - val_loss: 0.0267 - val_acc: 0.8272\n",
      "Epoch 6/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0266 - acc: 0.8278 - val_loss: 0.0267 - val_acc: 0.8265\n",
      "Epoch 7/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0266 - acc: 0.8282 - val_loss: 0.0267 - val_acc: 0.8272\n",
      "Epoch 8/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0265 - acc: 0.8282 - val_loss: 0.0267 - val_acc: 0.8266\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0265 - acc: 0.8280 - val_loss: 0.0267 - val_acc: 0.8276\n",
      "Epoch 10/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0265 - acc: 0.8282 - val_loss: 0.0267 - val_acc: 0.8278\n",
      "Epoch 11/24\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0265 - acc: 0.8283 - val_loss: 0.0266 - val_acc: 0.8274\n",
      "Epoch 12/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0265 - acc: 0.8285 - val_loss: 0.0266 - val_acc: 0.8270\n",
      "Epoch 13/24\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0264 - acc: 0.8287 - val_loss: 0.0266 - val_acc: 0.8274\n",
      "Epoch 14/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0264 - acc: 0.8287 - val_loss: 0.0266 - val_acc: 0.8275\n",
      "Epoch 15/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0264 - acc: 0.8290 - val_loss: 0.0266 - val_acc: 0.8275\n",
      "Epoch 16/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0264 - acc: 0.8290 - val_loss: 0.0265 - val_acc: 0.8278\n",
      "Epoch 17/24\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0264 - acc: 0.8291 - val_loss: 0.0265 - val_acc: 0.8291\n",
      "Epoch 18/24\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0263 - acc: 0.8290 - val_loss: 0.0265 - val_acc: 0.8274\n",
      "Epoch 19/24\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0263 - acc: 0.8294 - val_loss: 0.0265 - val_acc: 0.8282\n",
      "Epoch 20/24\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0263 - acc: 0.8295 - val_loss: 0.0265 - val_acc: 0.8280\n",
      "Epoch 21/24\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0263 - acc: 0.8296 - val_loss: 0.0265 - val_acc: 0.8283\n",
      "Epoch 22/24\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0263 - acc: 0.8298 - val_loss: 0.0264 - val_acc: 0.8285\n",
      "Epoch 23/24\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0263 - acc: 0.8297 - val_loss: 0.0264 - val_acc: 0.8283\n",
      "Epoch 24/24\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0262 - acc: 0.8299 - val_loss: 0.0264 - val_acc: 0.8288\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0262 - acc: 0.8299 - val_loss: 0.0264 - val_acc: 0.8286\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0262 - acc: 0.8301 - val_loss: 0.0264 - val_acc: 0.8282\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0262 - acc: 0.8302 - val_loss: 0.0263 - val_acc: 0.8285\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0262 - acc: 0.8303 - val_loss: 0.0263 - val_acc: 0.8289\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0262 - acc: 0.8305 - val_loss: 0.0263 - val_acc: 0.8284\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0261 - acc: 0.8303 - val_loss: 0.0263 - val_acc: 0.8286\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0261 - acc: 0.8307 - val_loss: 0.0263 - val_acc: 0.8291\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0261 - acc: 0.8307 - val_loss: 0.0263 - val_acc: 0.8289\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0261 - acc: 0.8306 - val_loss: 0.0262 - val_acc: 0.8290\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0261 - acc: 0.8308 - val_loss: 0.0262 - val_acc: 0.8291\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0261 - acc: 0.8308 - val_loss: 0.0262 - val_acc: 0.8288\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0260 - acc: 0.8307 - val_loss: 0.0262 - val_acc: 0.8292\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0260 - acc: 0.8310 - val_loss: 0.0262 - val_acc: 0.8292\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0260 - acc: 0.8311 - val_loss: 0.0262 - val_acc: 0.8295\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0260 - acc: 0.8312 - val_loss: 0.0261 - val_acc: 0.8297\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0260 - acc: 0.8312 - val_loss: 0.0261 - val_acc: 0.8295\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0260 - acc: 0.8313 - val_loss: 0.0261 - val_acc: 0.8299\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0259 - acc: 0.8313 - val_loss: 0.0261 - val_acc: 0.8300\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0259 - acc: 0.8314 - val_loss: 0.0261 - val_acc: 0.8294\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0259 - acc: 0.8315 - val_loss: 0.0261 - val_acc: 0.8300\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0259 - acc: 0.8314 - val_loss: 0.0261 - val_acc: 0.8300\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0259 - acc: 0.8317 - val_loss: 0.0260 - val_acc: 0.8299\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0259 - acc: 0.8317 - val_loss: 0.0260 - val_acc: 0.8304\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0258 - acc: 0.8315 - val_loss: 0.0260 - val_acc: 0.8302\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0258 - acc: 0.8318 - val_loss: 0.0260 - val_acc: 0.8304\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/26\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0258 - acc: 0.8318 - val_loss: 0.0260 - val_acc: 0.8304\n",
      "Epoch 2/26\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0258 - acc: 0.8321 - val_loss: 0.0260 - val_acc: 0.8304\n",
      "Epoch 3/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0258 - acc: 0.8321 - val_loss: 0.0259 - val_acc: 0.8305\n",
      "Epoch 4/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0258 - acc: 0.8322 - val_loss: 0.0259 - val_acc: 0.8306\n",
      "Epoch 5/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0257 - acc: 0.8321 - val_loss: 0.0259 - val_acc: 0.8307\n",
      "Epoch 6/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0257 - acc: 0.8323 - val_loss: 0.0259 - val_acc: 0.8311\n",
      "Epoch 7/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0257 - acc: 0.8324 - val_loss: 0.0259 - val_acc: 0.8308\n",
      "Epoch 8/26\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0257 - acc: 0.8325 - val_loss: 0.0259 - val_acc: 0.8317\n",
      "Epoch 9/26\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0257 - acc: 0.8324 - val_loss: 0.0259 - val_acc: 0.8314\n",
      "Epoch 10/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0257 - acc: 0.8329 - val_loss: 0.0258 - val_acc: 0.8316\n",
      "Epoch 11/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0257 - acc: 0.8326 - val_loss: 0.0258 - val_acc: 0.8318\n",
      "Epoch 12/26\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0256 - acc: 0.8328 - val_loss: 0.0258 - val_acc: 0.8321\n",
      "Epoch 13/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0256 - acc: 0.8330 - val_loss: 0.0258 - val_acc: 0.8319\n",
      "Epoch 14/26\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0256 - acc: 0.8331 - val_loss: 0.0258 - val_acc: 0.8319\n",
      "Epoch 15/26\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0256 - acc: 0.8331 - val_loss: 0.0258 - val_acc: 0.8321\n",
      "Epoch 16/26\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0256 - acc: 0.8333 - val_loss: 0.0258 - val_acc: 0.8320\n",
      "Epoch 17/26\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0256 - acc: 0.8330 - val_loss: 0.0257 - val_acc: 0.8324\n",
      "Epoch 18/26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0256 - acc: 0.8333 - val_loss: 0.0257 - val_acc: 0.8320\n",
      "Epoch 19/26\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0255 - acc: 0.8336 - val_loss: 0.0257 - val_acc: 0.8321\n",
      "Epoch 20/26\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0255 - acc: 0.8334 - val_loss: 0.0257 - val_acc: 0.8322\n",
      "Epoch 21/26\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0255 - acc: 0.8335 - val_loss: 0.0257 - val_acc: 0.8325\n",
      "Epoch 22/26\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0255 - acc: 0.8336 - val_loss: 0.0257 - val_acc: 0.8324\n",
      "Epoch 23/26\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0255 - acc: 0.8337 - val_loss: 0.0257 - val_acc: 0.8324\n",
      "Epoch 24/26\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0255 - acc: 0.8339 - val_loss: 0.0256 - val_acc: 0.8319\n",
      "Epoch 25/26\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0255 - acc: 0.8339 - val_loss: 0.0256 - val_acc: 0.8327\n",
      "Epoch 26/26\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0254 - acc: 0.8339 - val_loss: 0.0256 - val_acc: 0.8322\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/27\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0254 - acc: 0.8343 - val_loss: 0.0256 - val_acc: 0.8322\n",
      "Epoch 2/27\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0254 - acc: 0.8343 - val_loss: 0.0256 - val_acc: 0.8317\n",
      "Epoch 3/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0254 - acc: 0.8342 - val_loss: 0.0256 - val_acc: 0.8323\n",
      "Epoch 4/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0254 - acc: 0.8343 - val_loss: 0.0256 - val_acc: 0.8326\n",
      "Epoch 5/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0254 - acc: 0.8345 - val_loss: 0.0255 - val_acc: 0.8322\n",
      "Epoch 6/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0254 - acc: 0.8345 - val_loss: 0.0255 - val_acc: 0.8323\n",
      "Epoch 7/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0253 - acc: 0.8349 - val_loss: 0.0255 - val_acc: 0.8325\n",
      "Epoch 8/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0253 - acc: 0.8345 - val_loss: 0.0255 - val_acc: 0.8326\n",
      "Epoch 9/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0253 - acc: 0.8349 - val_loss: 0.0255 - val_acc: 0.8322\n",
      "Epoch 10/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0253 - acc: 0.8349 - val_loss: 0.0255 - val_acc: 0.8328\n",
      "Epoch 11/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0253 - acc: 0.8349 - val_loss: 0.0255 - val_acc: 0.8321\n",
      "Epoch 12/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0253 - acc: 0.8351 - val_loss: 0.0254 - val_acc: 0.8329\n",
      "Epoch 13/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0253 - acc: 0.8351 - val_loss: 0.0254 - val_acc: 0.8326\n",
      "Epoch 14/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0252 - acc: 0.8351 - val_loss: 0.0254 - val_acc: 0.8330\n",
      "Epoch 15/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0252 - acc: 0.8352 - val_loss: 0.0254 - val_acc: 0.8326\n",
      "Epoch 16/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0252 - acc: 0.8352 - val_loss: 0.0254 - val_acc: 0.8328\n",
      "Epoch 17/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0252 - acc: 0.8355 - val_loss: 0.0254 - val_acc: 0.8330\n",
      "Epoch 18/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0252 - acc: 0.8355 - val_loss: 0.0254 - val_acc: 0.8329\n",
      "Epoch 19/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0252 - acc: 0.8356 - val_loss: 0.0254 - val_acc: 0.8328\n",
      "Epoch 20/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0252 - acc: 0.8356 - val_loss: 0.0253 - val_acc: 0.8331\n",
      "Epoch 21/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0252 - acc: 0.8358 - val_loss: 0.0253 - val_acc: 0.8328\n",
      "Epoch 22/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0251 - acc: 0.8358 - val_loss: 0.0253 - val_acc: 0.8331\n",
      "Epoch 23/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0251 - acc: 0.8358 - val_loss: 0.0253 - val_acc: 0.8334\n",
      "Epoch 24/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0251 - acc: 0.8358 - val_loss: 0.0253 - val_acc: 0.8335\n",
      "Epoch 25/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0251 - acc: 0.8359 - val_loss: 0.0253 - val_acc: 0.8331\n",
      "Epoch 26/27\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0251 - acc: 0.8360 - val_loss: 0.0253 - val_acc: 0.8332\n",
      "Epoch 27/27\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0251 - acc: 0.8360 - val_loss: 0.0253 - val_acc: 0.8333\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0251 - acc: 0.8363 - val_loss: 0.0252 - val_acc: 0.8334\n",
      "Epoch 2/28\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0251 - acc: 0.8361 - val_loss: 0.0252 - val_acc: 0.8338\n",
      "Epoch 3/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0250 - acc: 0.8363 - val_loss: 0.0252 - val_acc: 0.8334\n",
      "Epoch 4/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0250 - acc: 0.8363 - val_loss: 0.0252 - val_acc: 0.8335\n",
      "Epoch 5/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0250 - acc: 0.8364 - val_loss: 0.0252 - val_acc: 0.8338\n",
      "Epoch 6/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0250 - acc: 0.8364 - val_loss: 0.0252 - val_acc: 0.8335\n",
      "Epoch 7/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0250 - acc: 0.8364 - val_loss: 0.0252 - val_acc: 0.8338\n",
      "Epoch 8/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0250 - acc: 0.8365 - val_loss: 0.0252 - val_acc: 0.8337\n",
      "Epoch 9/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0250 - acc: 0.8364 - val_loss: 0.0251 - val_acc: 0.8342\n",
      "Epoch 10/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0250 - acc: 0.8366 - val_loss: 0.0251 - val_acc: 0.8340\n",
      "Epoch 11/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0249 - acc: 0.8368 - val_loss: 0.0251 - val_acc: 0.8343\n",
      "Epoch 12/28\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0249 - acc: 0.8368 - val_loss: 0.0251 - val_acc: 0.8344\n",
      "Epoch 13/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0249 - acc: 0.8370 - val_loss: 0.0251 - val_acc: 0.8349\n",
      "Epoch 14/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0249 - acc: 0.8371 - val_loss: 0.0251 - val_acc: 0.8343\n",
      "Epoch 15/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0249 - acc: 0.8370 - val_loss: 0.0251 - val_acc: 0.8353\n",
      "Epoch 16/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0249 - acc: 0.8370 - val_loss: 0.0251 - val_acc: 0.8346\n",
      "Epoch 17/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0249 - acc: 0.8373 - val_loss: 0.0251 - val_acc: 0.8349\n",
      "Epoch 18/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0249 - acc: 0.8372 - val_loss: 0.0250 - val_acc: 0.8354\n",
      "Epoch 19/28\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0248 - acc: 0.8376 - val_loss: 0.0250 - val_acc: 0.8349\n",
      "Epoch 20/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0248 - acc: 0.8374 - val_loss: 0.0250 - val_acc: 0.8350\n",
      "Epoch 21/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0248 - acc: 0.8373 - val_loss: 0.0250 - val_acc: 0.8353\n",
      "Epoch 22/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0248 - acc: 0.8375 - val_loss: 0.0250 - val_acc: 0.8353\n",
      "Epoch 23/28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0248 - acc: 0.8379 - val_loss: 0.0250 - val_acc: 0.8357\n",
      "Epoch 24/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0248 - acc: 0.8375 - val_loss: 0.0250 - val_acc: 0.8353\n",
      "Epoch 25/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0248 - acc: 0.8377 - val_loss: 0.0250 - val_acc: 0.8349\n",
      "Epoch 26/28\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0248 - acc: 0.8377 - val_loss: 0.0250 - val_acc: 0.8358\n",
      "Epoch 27/28\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0248 - acc: 0.8380 - val_loss: 0.0249 - val_acc: 0.8358\n",
      "Epoch 28/28\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0247 - acc: 0.8378 - val_loss: 0.0249 - val_acc: 0.8354\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0247 - acc: 0.8378 - val_loss: 0.0249 - val_acc: 0.8354\n",
      "Epoch 2/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0247 - acc: 0.8382 - val_loss: 0.0249 - val_acc: 0.8354\n",
      "Epoch 3/29\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0247 - acc: 0.8379 - val_loss: 0.0249 - val_acc: 0.8361\n",
      "Epoch 4/29\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0247 - acc: 0.8381 - val_loss: 0.0249 - val_acc: 0.8355\n",
      "Epoch 5/29\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0247 - acc: 0.8382 - val_loss: 0.0249 - val_acc: 0.8357\n",
      "Epoch 6/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0247 - acc: 0.8382 - val_loss: 0.0249 - val_acc: 0.8356\n",
      "Epoch 7/29\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0247 - acc: 0.8382 - val_loss: 0.0249 - val_acc: 0.8357\n",
      "Epoch 8/29\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0247 - acc: 0.8383 - val_loss: 0.0248 - val_acc: 0.8347\n",
      "Epoch 9/29\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0246 - acc: 0.8384 - val_loss: 0.0248 - val_acc: 0.8356\n",
      "Epoch 10/29\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0246 - acc: 0.8384 - val_loss: 0.0248 - val_acc: 0.8359\n",
      "Epoch 11/29\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0246 - acc: 0.8387 - val_loss: 0.0248 - val_acc: 0.8354\n",
      "Epoch 12/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0246 - acc: 0.8385 - val_loss: 0.0248 - val_acc: 0.8354\n",
      "Epoch 13/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0246 - acc: 0.8387 - val_loss: 0.0248 - val_acc: 0.8353\n",
      "Epoch 14/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0246 - acc: 0.8386 - val_loss: 0.0248 - val_acc: 0.8362\n",
      "Epoch 15/29\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0246 - acc: 0.8387 - val_loss: 0.0248 - val_acc: 0.8358\n",
      "Epoch 16/29\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0246 - acc: 0.8387 - val_loss: 0.0248 - val_acc: 0.8349\n",
      "Epoch 17/29\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0246 - acc: 0.8390 - val_loss: 0.0247 - val_acc: 0.8355\n",
      "Epoch 18/29\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0245 - acc: 0.8389 - val_loss: 0.0247 - val_acc: 0.8355\n",
      "Epoch 19/29\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0245 - acc: 0.8393 - val_loss: 0.0247 - val_acc: 0.8360\n",
      "Epoch 20/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0245 - acc: 0.8389 - val_loss: 0.0247 - val_acc: 0.8357\n",
      "Epoch 21/29\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0245 - acc: 0.8390 - val_loss: 0.0247 - val_acc: 0.8356\n",
      "Epoch 22/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0245 - acc: 0.8393 - val_loss: 0.0247 - val_acc: 0.8362\n",
      "Epoch 23/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0245 - acc: 0.8392 - val_loss: 0.0247 - val_acc: 0.8363\n",
      "Epoch 24/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0245 - acc: 0.8393 - val_loss: 0.0247 - val_acc: 0.8362\n",
      "Epoch 25/29\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0245 - acc: 0.8393 - val_loss: 0.0247 - val_acc: 0.8363\n",
      "Epoch 26/29\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0245 - acc: 0.8394 - val_loss: 0.0247 - val_acc: 0.8364\n",
      "Epoch 27/29\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0244 - acc: 0.8395 - val_loss: 0.0246 - val_acc: 0.8365\n",
      "Epoch 28/29\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0244 - acc: 0.8395 - val_loss: 0.0246 - val_acc: 0.8363\n",
      "Epoch 29/29\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0244 - acc: 0.8396 - val_loss: 0.0246 - val_acc: 0.8365\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0244 - acc: 0.8395 - val_loss: 0.0246 - val_acc: 0.8364\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0244 - acc: 0.8397 - val_loss: 0.0246 - val_acc: 0.8362\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0244 - acc: 0.8399 - val_loss: 0.0246 - val_acc: 0.8366\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0244 - acc: 0.8396 - val_loss: 0.0246 - val_acc: 0.8369\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0244 - acc: 0.8398 - val_loss: 0.0246 - val_acc: 0.8365\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0244 - acc: 0.8400 - val_loss: 0.0246 - val_acc: 0.8369\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0244 - acc: 0.8401 - val_loss: 0.0246 - val_acc: 0.8363\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0243 - acc: 0.8401 - val_loss: 0.0245 - val_acc: 0.8369\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0243 - acc: 0.8400 - val_loss: 0.0245 - val_acc: 0.8368\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0243 - acc: 0.8401 - val_loss: 0.0245 - val_acc: 0.8371\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0243 - acc: 0.8402 - val_loss: 0.0245 - val_acc: 0.8370\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0243 - acc: 0.8404 - val_loss: 0.0245 - val_acc: 0.8374\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0243 - acc: 0.8404 - val_loss: 0.0245 - val_acc: 0.8372\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0243 - acc: 0.8404 - val_loss: 0.0245 - val_acc: 0.8374\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0243 - acc: 0.8406 - val_loss: 0.0245 - val_acc: 0.8371\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0242 - acc: 0.840 - 1s 23us/sample - loss: 0.0243 - acc: 0.8406 - val_loss: 0.0245 - val_acc: 0.8373\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0243 - acc: 0.8404 - val_loss: 0.0245 - val_acc: 0.8373\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0242 - acc: 0.8406 - val_loss: 0.0244 - val_acc: 0.8375\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0242 - acc: 0.8408 - val_loss: 0.0244 - val_acc: 0.8377\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0242 - acc: 0.8408 - val_loss: 0.0244 - val_acc: 0.8378\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0242 - acc: 0.8408 - val_loss: 0.0244 - val_acc: 0.8382\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0242 - acc: 0.8411 - val_loss: 0.0244 - val_acc: 0.8379\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0242 - acc: 0.8408 - val_loss: 0.0244 - val_acc: 0.8381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0242 - acc: 0.8410 - val_loss: 0.0244 - val_acc: 0.8382\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0242 - acc: 0.8409 - val_loss: 0.0244 - val_acc: 0.8384\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0242 - acc: 0.8413 - val_loss: 0.0244 - val_acc: 0.8386\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0242 - acc: 0.8410 - val_loss: 0.0244 - val_acc: 0.8388\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0241 - acc: 0.8412 - val_loss: 0.0244 - val_acc: 0.8387\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0241 - acc: 0.8414 - val_loss: 0.0243 - val_acc: 0.8383\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0241 - acc: 0.8411 - val_loss: 0.0243 - val_acc: 0.8386\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/31\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0241 - acc: 0.8413 - val_loss: 0.0243 - val_acc: 0.8388\n",
      "Epoch 2/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0241 - acc: 0.8413 - val_loss: 0.0243 - val_acc: 0.8387\n",
      "Epoch 3/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0241 - acc: 0.8415 - val_loss: 0.0243 - val_acc: 0.8386\n",
      "Epoch 4/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0241 - acc: 0.8414 - val_loss: 0.0243 - val_acc: 0.8389\n",
      "Epoch 5/31\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0241 - acc: 0.8414 - val_loss: 0.0243 - val_acc: 0.8390\n",
      "Epoch 6/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0241 - acc: 0.8417 - val_loss: 0.0243 - val_acc: 0.8388\n",
      "Epoch 7/31\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0241 - acc: 0.8417 - val_loss: 0.0243 - val_acc: 0.8389\n",
      "Epoch 8/31\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0241 - acc: 0.8415 - val_loss: 0.0243 - val_acc: 0.8389\n",
      "Epoch 9/31\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0240 - acc: 0.8414 - val_loss: 0.0243 - val_acc: 0.8390\n",
      "Epoch 10/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0240 - acc: 0.8418 - val_loss: 0.0242 - val_acc: 0.8393\n",
      "Epoch 11/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0240 - acc: 0.8417 - val_loss: 0.0242 - val_acc: 0.8392\n",
      "Epoch 12/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0240 - acc: 0.8419 - val_loss: 0.0242 - val_acc: 0.8391\n",
      "Epoch 13/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0240 - acc: 0.8418 - val_loss: 0.0242 - val_acc: 0.8395\n",
      "Epoch 14/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0240 - acc: 0.8419 - val_loss: 0.0242 - val_acc: 0.8393\n",
      "Epoch 15/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0240 - acc: 0.8418 - val_loss: 0.0242 - val_acc: 0.8389\n",
      "Epoch 16/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0240 - acc: 0.8420 - val_loss: 0.0242 - val_acc: 0.8387\n",
      "Epoch 17/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0240 - acc: 0.8420 - val_loss: 0.0242 - val_acc: 0.8394\n",
      "Epoch 18/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0240 - acc: 0.8421 - val_loss: 0.0242 - val_acc: 0.8397\n",
      "Epoch 19/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0240 - acc: 0.8420 - val_loss: 0.0242 - val_acc: 0.8391\n",
      "Epoch 20/31\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0239 - acc: 0.8419 - val_loss: 0.0242 - val_acc: 0.8393\n",
      "Epoch 21/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0239 - acc: 0.8420 - val_loss: 0.0242 - val_acc: 0.8395\n",
      "Epoch 22/31\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0239 - acc: 0.8421 - val_loss: 0.0241 - val_acc: 0.8394\n",
      "Epoch 23/31\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0239 - acc: 0.8422 - val_loss: 0.0241 - val_acc: 0.8394\n",
      "Epoch 24/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0239 - acc: 0.8422 - val_loss: 0.0241 - val_acc: 0.8393\n",
      "Epoch 25/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0239 - acc: 0.8422 - val_loss: 0.0241 - val_acc: 0.8394\n",
      "Epoch 26/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0239 - acc: 0.8425 - val_loss: 0.0241 - val_acc: 0.8394\n",
      "Epoch 27/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0239 - acc: 0.8423 - val_loss: 0.0241 - val_acc: 0.8399\n",
      "Epoch 28/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0239 - acc: 0.8424 - val_loss: 0.0241 - val_acc: 0.8393\n",
      "Epoch 29/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0239 - acc: 0.8426 - val_loss: 0.0241 - val_acc: 0.8399\n",
      "Epoch 30/31\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0239 - acc: 0.8427 - val_loss: 0.0241 - val_acc: 0.8400\n",
      "Epoch 31/31\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0238 - acc: 0.8425 - val_loss: 0.0241 - val_acc: 0.8401\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0238 - acc: 0.8426 - val_loss: 0.0241 - val_acc: 0.8401\n",
      "Epoch 2/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0238 - acc: 0.8427 - val_loss: 0.0241 - val_acc: 0.8400\n",
      "Epoch 3/32\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0238 - acc: 0.8426 - val_loss: 0.0240 - val_acc: 0.8400\n",
      "Epoch 4/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0238 - acc: 0.8424 - val_loss: 0.0240 - val_acc: 0.8404\n",
      "Epoch 5/32\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0238 - acc: 0.8428 - val_loss: 0.0240 - val_acc: 0.8401\n",
      "Epoch 6/32\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0238 - acc: 0.8428 - val_loss: 0.0240 - val_acc: 0.8406\n",
      "Epoch 7/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0238 - acc: 0.8428 - val_loss: 0.0240 - val_acc: 0.8403\n",
      "Epoch 8/32\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0238 - acc: 0.8427 - val_loss: 0.0240 - val_acc: 0.8405\n",
      "Epoch 9/32\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0238 - acc: 0.8432 - val_loss: 0.0240 - val_acc: 0.8404\n",
      "Epoch 10/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0238 - acc: 0.8431 - val_loss: 0.0240 - val_acc: 0.8407\n",
      "Epoch 11/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0238 - acc: 0.8432 - val_loss: 0.0240 - val_acc: 0.8407\n",
      "Epoch 12/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0237 - acc: 0.8431 - val_loss: 0.0240 - val_acc: 0.8410\n",
      "Epoch 13/32\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0237 - acc: 0.8430 - val_loss: 0.0240 - val_acc: 0.8410\n",
      "Epoch 14/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0237 - acc: 0.8431 - val_loss: 0.0240 - val_acc: 0.8409\n",
      "Epoch 15/32\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0237 - acc: 0.8432 - val_loss: 0.0239 - val_acc: 0.8407\n",
      "Epoch 16/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0237 - acc: 0.8430 - val_loss: 0.0239 - val_acc: 0.8407\n",
      "Epoch 17/32\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0237 - acc: 0.8432 - val_loss: 0.0239 - val_acc: 0.8411\n",
      "Epoch 18/32\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0237 - acc: 0.8434 - val_loss: 0.0239 - val_acc: 0.8412\n",
      "Epoch 19/32\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0237 - acc: 0.8436 - val_loss: 0.0239 - val_acc: 0.8413\n",
      "Epoch 20/32\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0237 - acc: 0.8435 - val_loss: 0.0239 - val_acc: 0.8414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/32\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0237 - acc: 0.8436 - val_loss: 0.0239 - val_acc: 0.8408\n",
      "Epoch 22/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0237 - acc: 0.8436 - val_loss: 0.0239 - val_acc: 0.8414\n",
      "Epoch 23/32\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0237 - acc: 0.8438 - val_loss: 0.0239 - val_acc: 0.8414\n",
      "Epoch 24/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0237 - acc: 0.8436 - val_loss: 0.0239 - val_acc: 0.8417\n",
      "Epoch 25/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8435 - val_loss: 0.0239 - val_acc: 0.8418\n",
      "Epoch 26/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8438 - val_loss: 0.0239 - val_acc: 0.8415\n",
      "Epoch 27/32\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0236 - acc: 0.8438 - val_loss: 0.0239 - val_acc: 0.8417\n",
      "Epoch 28/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8438 - val_loss: 0.0238 - val_acc: 0.8417\n",
      "Epoch 29/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8440 - val_loss: 0.0238 - val_acc: 0.8417\n",
      "Epoch 30/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8439 - val_loss: 0.0238 - val_acc: 0.8417\n",
      "Epoch 31/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8440 - val_loss: 0.0238 - val_acc: 0.8416\n",
      "Epoch 32/32\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8439 - val_loss: 0.0238 - val_acc: 0.8417\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/33\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0236 - acc: 0.8440 - val_loss: 0.0238 - val_acc: 0.8414\n",
      "Epoch 2/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8442 - val_loss: 0.0238 - val_acc: 0.8416\n",
      "Epoch 3/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8444 - val_loss: 0.0238 - val_acc: 0.8415\n",
      "Epoch 4/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0236 - acc: 0.8442 - val_loss: 0.0238 - val_acc: 0.8416\n",
      "Epoch 5/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8442 - val_loss: 0.0238 - val_acc: 0.8418\n",
      "Epoch 6/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8443 - val_loss: 0.0238 - val_acc: 0.8418\n",
      "Epoch 7/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8446 - val_loss: 0.0238 - val_acc: 0.8422\n",
      "Epoch 8/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8446 - val_loss: 0.0238 - val_acc: 0.8420\n",
      "Epoch 9/33\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0235 - acc: 0.8446 - val_loss: 0.0237 - val_acc: 0.8424\n",
      "Epoch 10/33\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0235 - acc: 0.8446 - val_loss: 0.0237 - val_acc: 0.8424\n",
      "Epoch 11/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8446 - val_loss: 0.0237 - val_acc: 0.8422\n",
      "Epoch 12/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8448 - val_loss: 0.0237 - val_acc: 0.8422\n",
      "Epoch 13/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8446 - val_loss: 0.0237 - val_acc: 0.8422\n",
      "Epoch 14/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8448 - val_loss: 0.0237 - val_acc: 0.8425\n",
      "Epoch 15/33\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0235 - acc: 0.8447 - val_loss: 0.0237 - val_acc: 0.8426\n",
      "Epoch 16/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0235 - acc: 0.8449 - val_loss: 0.0237 - val_acc: 0.8425\n",
      "Epoch 17/33\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0235 - acc: 0.8450 - val_loss: 0.0237 - val_acc: 0.8427\n",
      "Epoch 18/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8448 - val_loss: 0.0237 - val_acc: 0.8425\n",
      "Epoch 19/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8450 - val_loss: 0.0237 - val_acc: 0.8426\n",
      "Epoch 20/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8450 - val_loss: 0.0237 - val_acc: 0.8429\n",
      "Epoch 21/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8451 - val_loss: 0.0237 - val_acc: 0.8428\n",
      "Epoch 22/33\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0234 - acc: 0.8450 - val_loss: 0.0237 - val_acc: 0.8428\n",
      "Epoch 23/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8454 - val_loss: 0.0237 - val_acc: 0.8430\n",
      "Epoch 24/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8451 - val_loss: 0.0236 - val_acc: 0.8429\n",
      "Epoch 25/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8453 - val_loss: 0.0236 - val_acc: 0.8430\n",
      "Epoch 26/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8453 - val_loss: 0.0236 - val_acc: 0.8431\n",
      "Epoch 27/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8454 - val_loss: 0.0236 - val_acc: 0.8430\n",
      "Epoch 28/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8454 - val_loss: 0.0236 - val_acc: 0.8430\n",
      "Epoch 29/33\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0234 - acc: 0.8457 - val_loss: 0.0236 - val_acc: 0.8429\n",
      "Epoch 30/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8457 - val_loss: 0.0236 - val_acc: 0.8431\n",
      "Epoch 31/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0234 - acc: 0.8457 - val_loss: 0.0236 - val_acc: 0.8434\n",
      "Epoch 32/33\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0233 - acc: 0.8454 - val_loss: 0.0236 - val_acc: 0.8435\n",
      "Epoch 33/33\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0233 - acc: 0.8456 - val_loss: 0.0236 - val_acc: 0.8434\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/34\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0233 - acc: 0.8459 - val_loss: 0.0236 - val_acc: 0.8434\n",
      "Epoch 2/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0233 - acc: 0.8458 - val_loss: 0.0236 - val_acc: 0.8437\n",
      "Epoch 3/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0233 - acc: 0.8458 - val_loss: 0.0236 - val_acc: 0.8434\n",
      "Epoch 4/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0233 - acc: 0.8462 - val_loss: 0.0236 - val_acc: 0.8436\n",
      "Epoch 5/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0233 - acc: 0.8459 - val_loss: 0.0235 - val_acc: 0.8436\n",
      "Epoch 6/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0233 - acc: 0.8461 - val_loss: 0.0235 - val_acc: 0.8436\n",
      "Epoch 7/34\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0233 - acc: 0.8461 - val_loss: 0.0235 - val_acc: 0.8441\n",
      "Epoch 8/34\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0233 - acc: 0.8459 - val_loss: 0.0235 - val_acc: 0.8435\n",
      "Epoch 9/34\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0233 - acc: 0.8461 - val_loss: 0.0235 - val_acc: 0.8434\n",
      "Epoch 10/34\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0233 - acc: 0.8463 - val_loss: 0.0235 - val_acc: 0.8434\n",
      "Epoch 11/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0233 - acc: 0.8463 - val_loss: 0.0235 - val_acc: 0.8438\n",
      "Epoch 12/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0233 - acc: 0.8464 - val_loss: 0.0235 - val_acc: 0.8440\n",
      "Epoch 13/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0232 - acc: 0.8464 - val_loss: 0.0235 - val_acc: 0.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/34\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0232 - acc: 0.8465 - val_loss: 0.0235 - val_acc: 0.8439\n",
      "Epoch 15/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0232 - acc: 0.8464 - val_loss: 0.0235 - val_acc: 0.8434\n",
      "Epoch 16/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0232 - acc: 0.8465 - val_loss: 0.0235 - val_acc: 0.8441\n",
      "Epoch 17/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0232 - acc: 0.8467 - val_loss: 0.0235 - val_acc: 0.8437\n",
      "Epoch 18/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0232 - acc: 0.8466 - val_loss: 0.0235 - val_acc: 0.8435\n",
      "Epoch 19/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0232 - acc: 0.8468 - val_loss: 0.0235 - val_acc: 0.8443\n",
      "Epoch 20/34\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0232 - acc: 0.8466 - val_loss: 0.0234 - val_acc: 0.8442\n",
      "Epoch 21/34\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0232 - acc: 0.8467 - val_loss: 0.0234 - val_acc: 0.8440\n",
      "Epoch 22/34\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0232 - acc: 0.8469 - val_loss: 0.0234 - val_acc: 0.8442\n",
      "Epoch 23/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0232 - acc: 0.8470 - val_loss: 0.0234 - val_acc: 0.8443\n",
      "Epoch 24/34\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0232 - acc: 0.8467 - val_loss: 0.0234 - val_acc: 0.8443\n",
      "Epoch 25/34\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0232 - acc: 0.8470 - val_loss: 0.0234 - val_acc: 0.8446\n",
      "Epoch 26/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0232 - acc: 0.8468 - val_loss: 0.0234 - val_acc: 0.8445\n",
      "Epoch 27/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8468 - val_loss: 0.0234 - val_acc: 0.8445\n",
      "Epoch 28/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8468 - val_loss: 0.0234 - val_acc: 0.8444\n",
      "Epoch 29/34\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0231 - acc: 0.8469 - val_loss: 0.0234 - val_acc: 0.8446\n",
      "Epoch 30/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8469 - val_loss: 0.0234 - val_acc: 0.8446\n",
      "Epoch 31/34\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0231 - acc: 0.8472 - val_loss: 0.0234 - val_acc: 0.8446\n",
      "Epoch 32/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8472 - val_loss: 0.0234 - val_acc: 0.8446\n",
      "Epoch 33/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8473 - val_loss: 0.0234 - val_acc: 0.8445\n",
      "Epoch 34/34\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8472 - val_loss: 0.0234 - val_acc: 0.8446\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8472 - val_loss: 0.0234 - val_acc: 0.8445\n",
      "Epoch 2/35\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0231 - acc: 0.8475 - val_loss: 0.0233 - val_acc: 0.8446\n",
      "Epoch 3/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8474 - val_loss: 0.0233 - val_acc: 0.8444\n",
      "Epoch 4/35\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0231 - acc: 0.8473 - val_loss: 0.0233 - val_acc: 0.8446\n",
      "Epoch 5/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8477 - val_loss: 0.0233 - val_acc: 0.8444\n",
      "Epoch 6/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0231 - acc: 0.8475 - val_loss: 0.0233 - val_acc: 0.8443\n",
      "Epoch 7/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0231 - acc: 0.8475 - val_loss: 0.0233 - val_acc: 0.8443\n",
      "Epoch 8/35\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0230 - acc: 0.8477 - val_loss: 0.0233 - val_acc: 0.8445\n",
      "Epoch 9/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0230 - acc: 0.8476 - val_loss: 0.0233 - val_acc: 0.8448\n",
      "Epoch 10/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0230 - acc: 0.8475 - val_loss: 0.0233 - val_acc: 0.8446\n",
      "Epoch 11/35\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0230 - acc: 0.8477 - val_loss: 0.0233 - val_acc: 0.8445\n",
      "Epoch 12/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0230 - acc: 0.8477 - val_loss: 0.0233 - val_acc: 0.8446\n",
      "Epoch 13/35\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0230 - acc: 0.8476 - val_loss: 0.0233 - val_acc: 0.8448\n",
      "Epoch 14/35\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0230 - acc: 0.8479 - val_loss: 0.0233 - val_acc: 0.8448\n",
      "Epoch 15/35\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0230 - acc: 0.8479 - val_loss: 0.0233 - val_acc: 0.8448\n",
      "Epoch 16/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0230 - acc: 0.8480 - val_loss: 0.0233 - val_acc: 0.8449\n",
      "Epoch 17/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0230 - acc: 0.8481 - val_loss: 0.0233 - val_acc: 0.8449\n",
      "Epoch 18/35\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0230 - acc: 0.8480 - val_loss: 0.0232 - val_acc: 0.8449\n",
      "Epoch 19/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0230 - acc: 0.8479 - val_loss: 0.0232 - val_acc: 0.8445\n",
      "Epoch 20/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0230 - acc: 0.8481 - val_loss: 0.0232 - val_acc: 0.8448\n",
      "Epoch 21/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0230 - acc: 0.8481 - val_loss: 0.0232 - val_acc: 0.8448\n",
      "Epoch 22/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0230 - acc: 0.8483 - val_loss: 0.0232 - val_acc: 0.8450\n",
      "Epoch 23/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0230 - acc: 0.8483 - val_loss: 0.0232 - val_acc: 0.8446\n",
      "Epoch 24/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8483 - val_loss: 0.0232 - val_acc: 0.8449\n",
      "Epoch 25/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8484 - val_loss: 0.0232 - val_acc: 0.8447\n",
      "Epoch 26/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0232 - val_acc: 0.8448\n",
      "Epoch 27/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0232 - val_acc: 0.8450\n",
      "Epoch 28/35\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0229 - acc: 0.8485 - val_loss: 0.0232 - val_acc: 0.8449\n",
      "Epoch 29/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8483 - val_loss: 0.0232 - val_acc: 0.8449\n",
      "Epoch 30/35\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0232 - val_acc: 0.8448\n",
      "Epoch 31/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0232 - val_acc: 0.8451\n",
      "Epoch 32/35\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0232 - val_acc: 0.8452\n",
      "Epoch 33/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0232 - val_acc: 0.8450\n",
      "Epoch 34/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0232 - val_acc: 0.8448\n",
      "Epoch 35/35\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0229 - acc: 0.8488 - val_loss: 0.0231 - val_acc: 0.8450\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0231 - val_acc: 0.8451\n",
      "Epoch 2/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0231 - val_acc: 0.8452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8486 - val_loss: 0.0231 - val_acc: 0.8450\n",
      "Epoch 4/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0229 - acc: 0.8487 - val_loss: 0.0231 - val_acc: 0.8450\n",
      "Epoch 5/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0228 - acc: 0.8490 - val_loss: 0.0231 - val_acc: 0.8447\n",
      "Epoch 6/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0228 - acc: 0.8488 - val_loss: 0.0231 - val_acc: 0.8452\n",
      "Epoch 7/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0228 - acc: 0.8489 - val_loss: 0.0231 - val_acc: 0.8455\n",
      "Epoch 8/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0228 - acc: 0.8490 - val_loss: 0.0231 - val_acc: 0.8454\n",
      "Epoch 9/36\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0228 - acc: 0.8492 - val_loss: 0.0231 - val_acc: 0.8454\n",
      "Epoch 10/36\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0228 - acc: 0.8489 - val_loss: 0.0231 - val_acc: 0.8453\n",
      "Epoch 11/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0228 - acc: 0.8493 - val_loss: 0.0231 - val_acc: 0.8452\n",
      "Epoch 12/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0228 - acc: 0.8492 - val_loss: 0.0231 - val_acc: 0.8451\n",
      "Epoch 13/36\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0228 - acc: 0.8491 - val_loss: 0.0231 - val_acc: 0.8454\n",
      "Epoch 14/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0228 - acc: 0.8496 - val_loss: 0.0231 - val_acc: 0.8455\n",
      "Epoch 15/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0228 - acc: 0.8493 - val_loss: 0.0231 - val_acc: 0.8455\n",
      "Epoch 16/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0228 - acc: 0.8494 - val_loss: 0.0231 - val_acc: 0.8455\n",
      "Epoch 17/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0228 - acc: 0.8495 - val_loss: 0.0231 - val_acc: 0.8455\n",
      "Epoch 18/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0228 - acc: 0.8493 - val_loss: 0.0230 - val_acc: 0.8454\n",
      "Epoch 19/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0228 - acc: 0.8494 - val_loss: 0.0230 - val_acc: 0.8458\n",
      "Epoch 20/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0228 - acc: 0.8496 - val_loss: 0.0230 - val_acc: 0.8459\n",
      "Epoch 21/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0228 - acc: 0.8494 - val_loss: 0.0230 - val_acc: 0.8458\n",
      "Epoch 22/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0227 - acc: 0.8496 - val_loss: 0.0230 - val_acc: 0.8460\n",
      "Epoch 23/36\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0227 - acc: 0.8496 - val_loss: 0.0230 - val_acc: 0.8457\n",
      "Epoch 24/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8499 - val_loss: 0.0230 - val_acc: 0.8457\n",
      "Epoch 25/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8499 - val_loss: 0.0230 - val_acc: 0.8458\n",
      "Epoch 26/36\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0227 - acc: 0.8499 - val_loss: 0.0230 - val_acc: 0.8459\n",
      "Epoch 27/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8497 - val_loss: 0.0230 - val_acc: 0.8463\n",
      "Epoch 28/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8498 - val_loss: 0.0230 - val_acc: 0.8461\n",
      "Epoch 29/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8496 - val_loss: 0.0230 - val_acc: 0.8460\n",
      "Epoch 30/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8499 - val_loss: 0.0230 - val_acc: 0.8459\n",
      "Epoch 31/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8500 - val_loss: 0.0230 - val_acc: 0.8461\n",
      "Epoch 32/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8500 - val_loss: 0.0230 - val_acc: 0.8458\n",
      "Epoch 33/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8500 - val_loss: 0.0230 - val_acc: 0.8462\n",
      "Epoch 34/36\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0227 - acc: 0.8501 - val_loss: 0.0230 - val_acc: 0.8459\n",
      "Epoch 35/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8500 - val_loss: 0.0230 - val_acc: 0.8464\n",
      "Epoch 36/36\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0227 - acc: 0.8502 - val_loss: 0.0229 - val_acc: 0.8461\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0227 - acc: 0.8501 - val_loss: 0.0229 - val_acc: 0.8459\n",
      "Epoch 2/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0227 - acc: 0.8503 - val_loss: 0.0229 - val_acc: 0.8464\n",
      "Epoch 3/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8503 - val_loss: 0.0229 - val_acc: 0.8462\n",
      "Epoch 4/37\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0226 - acc: 0.8506 - val_loss: 0.0229 - val_acc: 0.8467\n",
      "Epoch 5/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8502 - val_loss: 0.0229 - val_acc: 0.8469\n",
      "Epoch 6/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8505 - val_loss: 0.0229 - val_acc: 0.8465\n",
      "Epoch 7/37\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0226 - acc: 0.8506 - val_loss: 0.0229 - val_acc: 0.8466\n",
      "Epoch 8/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8506 - val_loss: 0.0229 - val_acc: 0.8471\n",
      "Epoch 9/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8505 - val_loss: 0.0229 - val_acc: 0.8467\n",
      "Epoch 10/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8503 - val_loss: 0.0229 - val_acc: 0.8470\n",
      "Epoch 11/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8508 - val_loss: 0.0229 - val_acc: 0.8471\n",
      "Epoch 12/37\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0226 - acc: 0.8510 - val_loss: 0.0229 - val_acc: 0.8471\n",
      "Epoch 13/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8510 - val_loss: 0.0229 - val_acc: 0.8473\n",
      "Epoch 14/37\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0226 - acc: 0.8508 - val_loss: 0.0229 - val_acc: 0.8474\n",
      "Epoch 15/37\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0226 - acc: 0.8507 - val_loss: 0.0229 - val_acc: 0.8473\n",
      "Epoch 16/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8508 - val_loss: 0.0229 - val_acc: 0.8471\n",
      "Epoch 17/37\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0226 - acc: 0.8508 - val_loss: 0.0229 - val_acc: 0.8471\n",
      "Epoch 18/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8509 - val_loss: 0.0229 - val_acc: 0.8474\n",
      "Epoch 19/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0226 - acc: 0.8510 - val_loss: 0.0228 - val_acc: 0.8475\n",
      "Epoch 20/37\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0225 - acc: 0.8511 - val_loss: 0.0228 - val_acc: 0.8477\n",
      "Epoch 21/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8512 - val_loss: 0.0228 - val_acc: 0.8477\n",
      "Epoch 22/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8514 - val_loss: 0.0228 - val_acc: 0.8480\n",
      "Epoch 23/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8510 - val_loss: 0.0228 - val_acc: 0.8478\n",
      "Epoch 24/37\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0225 - acc: 0.8511 - val_loss: 0.0228 - val_acc: 0.8480\n",
      "Epoch 25/37\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0225 - acc: 0.8512 - val_loss: 0.0228 - val_acc: 0.8478\n",
      "Epoch 26/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8515 - val_loss: 0.0228 - val_acc: 0.8480\n",
      "Epoch 27/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8513 - val_loss: 0.0228 - val_acc: 0.8482\n",
      "Epoch 28/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8513 - val_loss: 0.0228 - val_acc: 0.8477\n",
      "Epoch 29/37\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0225 - acc: 0.8513 - val_loss: 0.0228 - val_acc: 0.8478\n",
      "Epoch 30/37\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0225 - acc: 0.8511 - val_loss: 0.0228 - val_acc: 0.8483\n",
      "Epoch 31/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8515 - val_loss: 0.0228 - val_acc: 0.8479\n",
      "Epoch 32/37\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0225 - acc: 0.8516 - val_loss: 0.0228 - val_acc: 0.8476\n",
      "Epoch 33/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8515 - val_loss: 0.0228 - val_acc: 0.8480\n",
      "Epoch 34/37\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0225 - acc: 0.8516 - val_loss: 0.0228 - val_acc: 0.8485\n",
      "Epoch 35/37\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0225 - acc: 0.8515 - val_loss: 0.0228 - val_acc: 0.8484\n",
      "Epoch 36/37\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0225 - acc: 0.8517 - val_loss: 0.0228 - val_acc: 0.8482\n",
      "Epoch 37/37\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0225 - acc: 0.8519 - val_loss: 0.0228 - val_acc: 0.8484\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0225 - acc: 0.8515 - val_loss: 0.0228 - val_acc: 0.8483\n",
      "Epoch 2/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8516 - val_loss: 0.0227 - val_acc: 0.8483\n",
      "Epoch 3/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8517 - val_loss: 0.0227 - val_acc: 0.8486\n",
      "Epoch 4/38\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0224 - acc: 0.8516 - val_loss: 0.0227 - val_acc: 0.8486\n",
      "Epoch 5/38\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0224 - acc: 0.8520 - val_loss: 0.0227 - val_acc: 0.8485\n",
      "Epoch 6/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0224 - acc: 0.8520 - val_loss: 0.0227 - val_acc: 0.8483\n",
      "Epoch 7/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0224 - acc: 0.8519 - val_loss: 0.0227 - val_acc: 0.8478\n",
      "Epoch 8/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0224 - acc: 0.8521 - val_loss: 0.0227 - val_acc: 0.8486\n",
      "Epoch 9/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0224 - acc: 0.8516 - val_loss: 0.0227 - val_acc: 0.8479\n",
      "Epoch 10/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8519 - val_loss: 0.0227 - val_acc: 0.8484\n",
      "Epoch 11/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8519 - val_loss: 0.0227 - val_acc: 0.8488\n",
      "Epoch 12/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8517 - val_loss: 0.0227 - val_acc: 0.8491\n",
      "Epoch 13/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8522 - val_loss: 0.0227 - val_acc: 0.8487\n",
      "Epoch 14/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8521 - val_loss: 0.0227 - val_acc: 0.8490\n",
      "Epoch 15/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8520 - val_loss: 0.0227 - val_acc: 0.8490\n",
      "Epoch 16/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8521 - val_loss: 0.0227 - val_acc: 0.8487\n",
      "Epoch 17/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8521 - val_loss: 0.0227 - val_acc: 0.8482\n",
      "Epoch 18/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0224 - acc: 0.8521 - val_loss: 0.0227 - val_acc: 0.8491\n",
      "Epoch 19/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8522 - val_loss: 0.0227 - val_acc: 0.8485\n",
      "Epoch 20/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0224 - acc: 0.8524 - val_loss: 0.0227 - val_acc: 0.8486\n",
      "Epoch 21/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0223 - acc: 0.8521 - val_loss: 0.0227 - val_acc: 0.8490\n",
      "Epoch 22/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8525 - val_loss: 0.0227 - val_acc: 0.8488\n",
      "Epoch 23/38\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0223 - acc: 0.8523 - val_loss: 0.0226 - val_acc: 0.8484\n",
      "Epoch 24/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8523 - val_loss: 0.0226 - val_acc: 0.8489\n",
      "Epoch 25/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0223 - acc: 0.8525 - val_loss: 0.0226 - val_acc: 0.8487\n",
      "Epoch 26/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8524 - val_loss: 0.0226 - val_acc: 0.8489\n",
      "Epoch 27/38\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0223 - acc: 0.8526 - val_loss: 0.0226 - val_acc: 0.8485\n",
      "Epoch 28/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8525 - val_loss: 0.0226 - val_acc: 0.8492\n",
      "Epoch 29/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8526 - val_loss: 0.0226 - val_acc: 0.8496\n",
      "Epoch 30/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8526 - val_loss: 0.0226 - val_acc: 0.8495\n",
      "Epoch 31/38\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0223 - acc: 0.8527 - val_loss: 0.0226 - val_acc: 0.8492\n",
      "Epoch 32/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8528 - val_loss: 0.0226 - val_acc: 0.8492\n",
      "Epoch 33/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8525 - val_loss: 0.0226 - val_acc: 0.8494\n",
      "Epoch 34/38\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0223 - acc: 0.8529 - val_loss: 0.0226 - val_acc: 0.8491\n",
      "Epoch 35/38\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0223 - acc: 0.8528 - val_loss: 0.0226 - val_acc: 0.8495\n",
      "Epoch 36/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8528 - val_loss: 0.0226 - val_acc: 0.8490\n",
      "Epoch 37/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8528 - val_loss: 0.0226 - val_acc: 0.8493\n",
      "Epoch 38/38\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8527 - val_loss: 0.0226 - val_acc: 0.8493\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0223 - acc: 0.8528 - val_loss: 0.0226 - val_acc: 0.8494\n",
      "Epoch 2/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8529 - val_loss: 0.0226 - val_acc: 0.8496\n",
      "Epoch 3/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8531 - val_loss: 0.0226 - val_acc: 0.8496\n",
      "Epoch 4/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8530 - val_loss: 0.0226 - val_acc: 0.8497\n",
      "Epoch 5/39\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0222 - acc: 0.8529 - val_loss: 0.0226 - val_acc: 0.8496\n",
      "Epoch 6/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8529 - val_loss: 0.0226 - val_acc: 0.8494\n",
      "Epoch 7/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8530 - val_loss: 0.0225 - val_acc: 0.8491\n",
      "Epoch 8/39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8532 - val_loss: 0.0225 - val_acc: 0.8493\n",
      "Epoch 9/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8532 - val_loss: 0.0225 - val_acc: 0.8495\n",
      "Epoch 10/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8532 - val_loss: 0.0225 - val_acc: 0.8495\n",
      "Epoch 11/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8532 - val_loss: 0.0225 - val_acc: 0.8494\n",
      "Epoch 12/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8532 - val_loss: 0.0225 - val_acc: 0.8493\n",
      "Epoch 13/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8533 - val_loss: 0.0225 - val_acc: 0.8495\n",
      "Epoch 14/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8532 - val_loss: 0.0225 - val_acc: 0.8493\n",
      "Epoch 15/39\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0222 - acc: 0.8532 - val_loss: 0.0225 - val_acc: 0.8497\n",
      "Epoch 16/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8533 - val_loss: 0.0225 - val_acc: 0.8496\n",
      "Epoch 17/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8535 - val_loss: 0.0225 - val_acc: 0.8492\n",
      "Epoch 18/39\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0222 - acc: 0.8533 - val_loss: 0.0225 - val_acc: 0.8493\n",
      "Epoch 19/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8532 - val_loss: 0.0225 - val_acc: 0.8493\n",
      "Epoch 20/39\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0222 - acc: 0.8533 - val_loss: 0.0225 - val_acc: 0.8489\n",
      "Epoch 21/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8535 - val_loss: 0.0225 - val_acc: 0.8494\n",
      "Epoch 22/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0222 - acc: 0.8534 - val_loss: 0.0225 - val_acc: 0.8495\n",
      "Epoch 23/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8537 - val_loss: 0.0225 - val_acc: 0.8497\n",
      "Epoch 24/39\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0221 - acc: 0.8533 - val_loss: 0.0225 - val_acc: 0.8499\n",
      "Epoch 25/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8536 - val_loss: 0.0225 - val_acc: 0.8499\n",
      "Epoch 26/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8536 - val_loss: 0.0225 - val_acc: 0.8500\n",
      "Epoch 27/39\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0221 - acc: 0.8536 - val_loss: 0.0225 - val_acc: 0.8497\n",
      "Epoch 28/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8536 - val_loss: 0.0225 - val_acc: 0.8494\n",
      "Epoch 29/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8535 - val_loss: 0.0225 - val_acc: 0.8494\n",
      "Epoch 30/39\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0221 - acc: 0.8538 - val_loss: 0.0224 - val_acc: 0.8497\n",
      "Epoch 31/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8536 - val_loss: 0.0224 - val_acc: 0.8497\n",
      "Epoch 32/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8537 - val_loss: 0.0224 - val_acc: 0.8498\n",
      "Epoch 33/39\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0221 - acc: 0.8536 - val_loss: 0.0224 - val_acc: 0.8493\n",
      "Epoch 34/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8538 - val_loss: 0.0224 - val_acc: 0.8494\n",
      "Epoch 35/39\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0221 - acc: 0.8540 - val_loss: 0.0224 - val_acc: 0.8498\n",
      "Epoch 36/39\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0221 - acc: 0.8538 - val_loss: 0.0224 - val_acc: 0.8495\n",
      "Epoch 37/39\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8539 - val_loss: 0.0224 - val_acc: 0.8497\n",
      "Epoch 38/39\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0221 - acc: 0.8538 - val_loss: 0.0224 - val_acc: 0.8496\n",
      "Epoch 39/39\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0221 - acc: 0.8536 - val_loss: 0.0224 - val_acc: 0.8493\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0221 - acc: 0.8539 - val_loss: 0.0224 - val_acc: 0.8496\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8537 - val_loss: 0.0224 - val_acc: 0.8496\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0221 - acc: 0.8538 - val_loss: 0.0224 - val_acc: 0.8493\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0221 - acc: 0.8540 - val_loss: 0.0224 - val_acc: 0.8493\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8540 - val_loss: 0.0224 - val_acc: 0.8495\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0220 - acc: 0.8538 - val_loss: 0.0224 - val_acc: 0.8496\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8541 - val_loss: 0.0224 - val_acc: 0.8493\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8538 - val_loss: 0.0224 - val_acc: 0.8495\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0220 - acc: 0.8538 - val_loss: 0.0224 - val_acc: 0.8499\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8539 - val_loss: 0.0224 - val_acc: 0.8494\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8540 - val_loss: 0.0224 - val_acc: 0.8496\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8540 - val_loss: 0.0224 - val_acc: 0.8497\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0220 - acc: 0.8540 - val_loss: 0.0224 - val_acc: 0.8497\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0220 - acc: 0.8541 - val_loss: 0.0223 - val_acc: 0.8498\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8540 - val_loss: 0.0223 - val_acc: 0.8500\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0220 - acc: 0.8545 - val_loss: 0.0223 - val_acc: 0.8499\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8543 - val_loss: 0.0223 - val_acc: 0.8498\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8542 - val_loss: 0.0223 - val_acc: 0.8501\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8544 - val_loss: 0.0223 - val_acc: 0.8499\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0220 - acc: 0.8544 - val_loss: 0.0223 - val_acc: 0.8498\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8542 - val_loss: 0.0223 - val_acc: 0.8497\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0220 - acc: 0.8543 - val_loss: 0.0223 - val_acc: 0.8499\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0220 - acc: 0.8542 - val_loss: 0.0223 - val_acc: 0.8499\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0220 - acc: 0.8545 - val_loss: 0.0223 - val_acc: 0.8496\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0220 - acc: 0.8544 - val_loss: 0.0223 - val_acc: 0.8501\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0219 - acc: 0.8544 - val_loss: 0.0223 - val_acc: 0.8497\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8547 - val_loss: 0.0223 - val_acc: 0.8501\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8545 - val_loss: 0.0223 - val_acc: 0.8500\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0219 - acc: 0.8546 - val_loss: 0.0223 - val_acc: 0.8497\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0219 - acc: 0.8546 - val_loss: 0.0223 - val_acc: 0.8502\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0219 - acc: 0.8546 - val_loss: 0.0223 - val_acc: 0.8496\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0219 - acc: 0.8545 - val_loss: 0.0223 - val_acc: 0.8503\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8546 - val_loss: 0.0223 - val_acc: 0.8501\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8547 - val_loss: 0.0223 - val_acc: 0.8502\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0219 - acc: 0.8548 - val_loss: 0.0223 - val_acc: 0.8502\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0219 - acc: 0.8547 - val_loss: 0.0223 - val_acc: 0.8496\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8546 - val_loss: 0.0223 - val_acc: 0.8498\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0219 - acc: 0.8549 - val_loss: 0.0222 - val_acc: 0.8501\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0219 - acc: 0.8548 - val_loss: 0.0222 - val_acc: 0.8501\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0219 - acc: 0.8550 - val_loss: 0.0222 - val_acc: 0.8501\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0219 - acc: 0.8550 - val_loss: 0.0222 - val_acc: 0.8503\n",
      "Epoch 2/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8551 - val_loss: 0.0222 - val_acc: 0.8501\n",
      "Epoch 3/41\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0219 - acc: 0.8550 - val_loss: 0.0222 - val_acc: 0.8504\n",
      "Epoch 4/41\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0219 - acc: 0.8550 - val_loss: 0.0222 - val_acc: 0.8504\n",
      "Epoch 5/41\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0219 - acc: 0.8550 - val_loss: 0.0222 - val_acc: 0.8499\n",
      "Epoch 6/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8551 - val_loss: 0.0222 - val_acc: 0.8504\n",
      "Epoch 7/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8551 - val_loss: 0.0222 - val_acc: 0.8498\n",
      "Epoch 8/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0219 - acc: 0.8552 - val_loss: 0.0222 - val_acc: 0.8500\n",
      "Epoch 9/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8551 - val_loss: 0.0222 - val_acc: 0.8502\n",
      "Epoch 10/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8551 - val_loss: 0.0222 - val_acc: 0.8506\n",
      "Epoch 11/41\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0218 - acc: 0.8550 - val_loss: 0.0222 - val_acc: 0.8503\n",
      "Epoch 12/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8549 - val_loss: 0.0222 - val_acc: 0.8506\n",
      "Epoch 13/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8551 - val_loss: 0.0222 - val_acc: 0.8504\n",
      "Epoch 14/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0218 - acc: 0.8552 - val_loss: 0.0222 - val_acc: 0.8504\n",
      "Epoch 15/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8551 - val_loss: 0.0222 - val_acc: 0.8507\n",
      "Epoch 16/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0218 - acc: 0.8553 - val_loss: 0.0222 - val_acc: 0.8507\n",
      "Epoch 17/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0218 - acc: 0.8552 - val_loss: 0.0222 - val_acc: 0.8508\n",
      "Epoch 18/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0218 - acc: 0.8554 - val_loss: 0.0222 - val_acc: 0.8500\n",
      "Epoch 19/41\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0218 - acc: 0.8551 - val_loss: 0.0222 - val_acc: 0.8503\n",
      "Epoch 20/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8554 - val_loss: 0.0222 - val_acc: 0.8506\n",
      "Epoch 21/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8555 - val_loss: 0.0222 - val_acc: 0.8507\n",
      "Epoch 22/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8554 - val_loss: 0.0222 - val_acc: 0.8505\n",
      "Epoch 23/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8553 - val_loss: 0.0222 - val_acc: 0.8504\n",
      "Epoch 24/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0218 - acc: 0.8553 - val_loss: 0.0221 - val_acc: 0.8504\n",
      "Epoch 25/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8557 - val_loss: 0.0221 - val_acc: 0.8512\n",
      "Epoch 26/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8554 - val_loss: 0.0221 - val_acc: 0.8510\n",
      "Epoch 27/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8555 - val_loss: 0.0221 - val_acc: 0.8508\n",
      "Epoch 28/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8554 - val_loss: 0.0221 - val_acc: 0.8507\n",
      "Epoch 29/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8557 - val_loss: 0.0221 - val_acc: 0.8506\n",
      "Epoch 30/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0218 - acc: 0.8556 - val_loss: 0.0221 - val_acc: 0.8507\n",
      "Epoch 31/41\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0218 - acc: 0.8554 - val_loss: 0.0221 - val_acc: 0.8508\n",
      "Epoch 32/41\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0217 - acc: 0.8557 - val_loss: 0.0221 - val_acc: 0.8508\n",
      "Epoch 33/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8558 - val_loss: 0.0221 - val_acc: 0.8512\n",
      "Epoch 34/41\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0217 - acc: 0.8556 - val_loss: 0.0221 - val_acc: 0.8506\n",
      "Epoch 35/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8557 - val_loss: 0.0221 - val_acc: 0.8511\n",
      "Epoch 36/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8558 - val_loss: 0.0221 - val_acc: 0.8514\n",
      "Epoch 37/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8559 - val_loss: 0.0221 - val_acc: 0.8511\n",
      "Epoch 38/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8556 - val_loss: 0.0221 - val_acc: 0.8517\n",
      "Epoch 39/41\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0217 - acc: 0.8556 - val_loss: 0.0221 - val_acc: 0.8513\n",
      "Epoch 40/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8558 - val_loss: 0.0221 - val_acc: 0.8515\n",
      "Epoch 41/41\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8559 - val_loss: 0.0221 - val_acc: 0.8519\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8561 - val_loss: 0.0221 - val_acc: 0.8513\n",
      "Epoch 2/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8559 - val_loss: 0.0221 - val_acc: 0.8515\n",
      "Epoch 3/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8560 - val_loss: 0.0221 - val_acc: 0.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8558 - val_loss: 0.0221 - val_acc: 0.8520\n",
      "Epoch 5/42\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0217 - acc: 0.8559 - val_loss: 0.0221 - val_acc: 0.8515\n",
      "Epoch 6/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0217 - acc: 0.8562 - val_loss: 0.0221 - val_acc: 0.8512\n",
      "Epoch 7/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8563 - val_loss: 0.0221 - val_acc: 0.8513\n",
      "Epoch 8/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0217 - acc: 0.8558 - val_loss: 0.0221 - val_acc: 0.8518\n",
      "Epoch 9/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8560 - val_loss: 0.0221 - val_acc: 0.8518\n",
      "Epoch 10/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8561 - val_loss: 0.0220 - val_acc: 0.8516\n",
      "Epoch 11/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0217 - acc: 0.8562 - val_loss: 0.0220 - val_acc: 0.8516\n",
      "Epoch 12/42\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0217 - acc: 0.8561 - val_loss: 0.0220 - val_acc: 0.8516\n",
      "Epoch 13/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0217 - acc: 0.8561 - val_loss: 0.0220 - val_acc: 0.8517\n",
      "Epoch 14/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8560 - val_loss: 0.0220 - val_acc: 0.8516\n",
      "Epoch 15/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8564 - val_loss: 0.0220 - val_acc: 0.8520\n",
      "Epoch 16/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8562 - val_loss: 0.0220 - val_acc: 0.8514\n",
      "Epoch 17/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8559 - val_loss: 0.0220 - val_acc: 0.8513\n",
      "Epoch 18/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8562 - val_loss: 0.0220 - val_acc: 0.8517\n",
      "Epoch 19/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8565 - val_loss: 0.0220 - val_acc: 0.8518\n",
      "Epoch 20/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8565 - val_loss: 0.0220 - val_acc: 0.8516\n",
      "Epoch 21/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8565 - val_loss: 0.0220 - val_acc: 0.8523\n",
      "Epoch 22/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8566 - val_loss: 0.0220 - val_acc: 0.8522\n",
      "Epoch 23/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8565 - val_loss: 0.0220 - val_acc: 0.8516\n",
      "Epoch 24/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8564 - val_loss: 0.0220 - val_acc: 0.8514\n",
      "Epoch 25/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8565 - val_loss: 0.0220 - val_acc: 0.8524\n",
      "Epoch 26/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8567 - val_loss: 0.0220 - val_acc: 0.8519\n",
      "Epoch 27/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8567 - val_loss: 0.0220 - val_acc: 0.8519\n",
      "Epoch 28/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8566 - val_loss: 0.0220 - val_acc: 0.8522\n",
      "Epoch 29/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8564 - val_loss: 0.0220 - val_acc: 0.8515\n",
      "Epoch 30/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8564 - val_loss: 0.0220 - val_acc: 0.8518\n",
      "Epoch 31/42\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0216 - acc: 0.8565 - val_loss: 0.0220 - val_acc: 0.8521\n",
      "Epoch 32/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8567 - val_loss: 0.0220 - val_acc: 0.8521\n",
      "Epoch 33/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8566 - val_loss: 0.0220 - val_acc: 0.8520\n",
      "Epoch 34/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8565 - val_loss: 0.0220 - val_acc: 0.8519\n",
      "Epoch 35/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8567 - val_loss: 0.0220 - val_acc: 0.8521\n",
      "Epoch 36/42\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0216 - acc: 0.8568 - val_loss: 0.0220 - val_acc: 0.8522\n",
      "Epoch 37/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0216 - acc: 0.8569 - val_loss: 0.0220 - val_acc: 0.8527\n",
      "Epoch 38/42\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0216 - acc: 0.8566 - val_loss: 0.0220 - val_acc: 0.8523\n",
      "Epoch 39/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8571 - val_loss: 0.0219 - val_acc: 0.8524\n",
      "Epoch 40/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8568 - val_loss: 0.0219 - val_acc: 0.8521\n",
      "Epoch 41/42\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8570 - val_loss: 0.0219 - val_acc: 0.8522\n",
      "Epoch 42/42\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0215 - acc: 0.8568 - val_loss: 0.0219 - val_acc: 0.8523\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0215 - acc: 0.8571 - val_loss: 0.0219 - val_acc: 0.8521\n",
      "Epoch 2/43\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0215 - acc: 0.8570 - val_loss: 0.0219 - val_acc: 0.8523\n",
      "Epoch 3/43\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0215 - acc: 0.8568 - val_loss: 0.0219 - val_acc: 0.8524\n",
      "Epoch 4/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8573 - val_loss: 0.0219 - val_acc: 0.8521\n",
      "Epoch 5/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0215 - acc: 0.8570 - val_loss: 0.0219 - val_acc: 0.8525\n",
      "Epoch 6/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0215 - acc: 0.8572 - val_loss: 0.0219 - val_acc: 0.8529\n",
      "Epoch 7/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0215 - acc: 0.8573 - val_loss: 0.0219 - val_acc: 0.8521\n",
      "Epoch 8/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8572 - val_loss: 0.0219 - val_acc: 0.8527\n",
      "Epoch 9/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0215 - acc: 0.8571 - val_loss: 0.0219 - val_acc: 0.8523\n",
      "Epoch 10/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0215 - acc: 0.8572 - val_loss: 0.0219 - val_acc: 0.8523\n",
      "Epoch 11/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8571 - val_loss: 0.0219 - val_acc: 0.8523\n",
      "Epoch 12/43\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0215 - acc: 0.8570 - val_loss: 0.0219 - val_acc: 0.8526\n",
      "Epoch 13/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8572 - val_loss: 0.0219 - val_acc: 0.8525\n",
      "Epoch 14/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8571 - val_loss: 0.0219 - val_acc: 0.8526\n",
      "Epoch 15/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8574 - val_loss: 0.0219 - val_acc: 0.8528\n",
      "Epoch 16/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8572 - val_loss: 0.0219 - val_acc: 0.8530\n",
      "Epoch 17/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8572 - val_loss: 0.0219 - val_acc: 0.8524\n",
      "Epoch 18/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8572 - val_loss: 0.0219 - val_acc: 0.8527\n",
      "Epoch 19/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0215 - acc: 0.8573 - val_loss: 0.0219 - val_acc: 0.8527\n",
      "Epoch 20/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8573 - val_loss: 0.0219 - val_acc: 0.8528\n",
      "Epoch 21/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8574 - val_loss: 0.0219 - val_acc: 0.8529\n",
      "Epoch 22/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0215 - acc: 0.8573 - val_loss: 0.0219 - val_acc: 0.8525\n",
      "Epoch 23/43\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0214 - acc: 0.8574 - val_loss: 0.0219 - val_acc: 0.8526\n",
      "Epoch 24/43\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0214 - acc: 0.8574 - val_loss: 0.0219 - val_acc: 0.8526\n",
      "Epoch 25/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8574 - val_loss: 0.0219 - val_acc: 0.8527\n",
      "Epoch 26/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8575 - val_loss: 0.0218 - val_acc: 0.8528\n",
      "Epoch 27/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8574 - val_loss: 0.0218 - val_acc: 0.8534\n",
      "Epoch 28/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8575 - val_loss: 0.0218 - val_acc: 0.8529\n",
      "Epoch 29/43\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0214 - acc: 0.8577 - val_loss: 0.0218 - val_acc: 0.8527\n",
      "Epoch 30/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8577 - val_loss: 0.0218 - val_acc: 0.8530\n",
      "Epoch 31/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8575 - val_loss: 0.0218 - val_acc: 0.8533\n",
      "Epoch 32/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8574 - val_loss: 0.0218 - val_acc: 0.8530\n",
      "Epoch 33/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8577 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 34/43\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0214 - acc: 0.8576 - val_loss: 0.0218 - val_acc: 0.8529\n",
      "Epoch 35/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8576 - val_loss: 0.0218 - val_acc: 0.8533\n",
      "Epoch 36/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0214 - acc: 0.8577 - val_loss: 0.0218 - val_acc: 0.8531\n",
      "Epoch 37/43\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0214 - acc: 0.8578 - val_loss: 0.0218 - val_acc: 0.8530\n",
      "Epoch 38/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8577 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 39/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8576 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 40/43\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0214 - acc: 0.8578 - val_loss: 0.0218 - val_acc: 0.8533\n",
      "Epoch 41/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8578 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 42/43\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0214 - acc: 0.8579 - val_loss: 0.0218 - val_acc: 0.8533\n",
      "Epoch 43/43\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8578 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8579 - val_loss: 0.0218 - val_acc: 0.8530\n",
      "Epoch 2/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8581 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 3/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8581 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 4/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8580 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 5/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0214 - acc: 0.8580 - val_loss: 0.0218 - val_acc: 0.8534\n",
      "Epoch 6/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8581 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 7/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0213 - acc: 0.8580 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 8/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8579 - val_loss: 0.0218 - val_acc: 0.8532\n",
      "Epoch 9/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0218 - val_acc: 0.8536\n",
      "Epoch 10/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8580 - val_loss: 0.0218 - val_acc: 0.8534\n",
      "Epoch 11/44\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0218 - val_acc: 0.8536\n",
      "Epoch 12/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8581 - val_loss: 0.0218 - val_acc: 0.8533\n",
      "Epoch 13/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8581 - val_loss: 0.0217 - val_acc: 0.8535\n",
      "Epoch 14/44\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0213 - acc: 0.8581 - val_loss: 0.0217 - val_acc: 0.8538\n",
      "Epoch 15/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8582 - val_loss: 0.0217 - val_acc: 0.8535\n",
      "Epoch 16/44\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0217 - val_acc: 0.8533\n",
      "Epoch 17/44\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0217 - val_acc: 0.8532\n",
      "Epoch 18/44\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0213 - acc: 0.8584 - val_loss: 0.0217 - val_acc: 0.8535\n",
      "Epoch 19/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0217 - val_acc: 0.8532\n",
      "Epoch 20/44\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0217 - val_acc: 0.8541\n",
      "Epoch 21/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8584 - val_loss: 0.0217 - val_acc: 0.8541\n",
      "Epoch 22/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0217 - val_acc: 0.8543\n",
      "Epoch 23/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0217 - val_acc: 0.8535\n",
      "Epoch 24/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0213 - acc: 0.8585 - val_loss: 0.0217 - val_acc: 0.8540\n",
      "Epoch 25/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8584 - val_loss: 0.0217 - val_acc: 0.8534\n",
      "Epoch 26/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0213 - acc: 0.8585 - val_loss: 0.0217 - val_acc: 0.8543\n",
      "Epoch 27/44\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0213 - acc: 0.858 - 1s 22us/sample - loss: 0.0213 - acc: 0.8587 - val_loss: 0.0217 - val_acc: 0.8543\n",
      "Epoch 28/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8583 - val_loss: 0.0217 - val_acc: 0.8537\n",
      "Epoch 29/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0213 - acc: 0.8585 - val_loss: 0.0217 - val_acc: 0.8536\n",
      "Epoch 30/44\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0213 - acc: 0.8586 - val_loss: 0.0217 - val_acc: 0.8538\n",
      "Epoch 31/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0213 - acc: 0.8587 - val_loss: 0.0217 - val_acc: 0.8535\n",
      "Epoch 32/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0213 - acc: 0.8587 - val_loss: 0.0217 - val_acc: 0.8537\n",
      "Epoch 33/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8587 - val_loss: 0.0217 - val_acc: 0.8544\n",
      "Epoch 34/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0212 - acc: 0.8588 - val_loss: 0.0217 - val_acc: 0.8539\n",
      "Epoch 35/44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8587 - val_loss: 0.0217 - val_acc: 0.8546\n",
      "Epoch 36/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0212 - acc: 0.8588 - val_loss: 0.0217 - val_acc: 0.8539\n",
      "Epoch 37/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0212 - acc: 0.8587 - val_loss: 0.0217 - val_acc: 0.8541\n",
      "Epoch 38/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8590 - val_loss: 0.0217 - val_acc: 0.8544\n",
      "Epoch 39/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0212 - acc: 0.8589 - val_loss: 0.0217 - val_acc: 0.8537\n",
      "Epoch 40/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8590 - val_loss: 0.0217 - val_acc: 0.8536\n",
      "Epoch 41/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8588 - val_loss: 0.0217 - val_acc: 0.8537\n",
      "Epoch 42/44\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0212 - acc: 0.8590 - val_loss: 0.0217 - val_acc: 0.8540\n",
      "Epoch 43/44\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0212 - acc: 0.8587 - val_loss: 0.0217 - val_acc: 0.8544\n",
      "Epoch 44/44\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8587 - val_loss: 0.0216 - val_acc: 0.8547\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8589 - val_loss: 0.0217 - val_acc: 0.8537\n",
      "Epoch 2/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8588 - val_loss: 0.0216 - val_acc: 0.8548\n",
      "Epoch 3/45\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0212 - acc: 0.8594 - val_loss: 0.0216 - val_acc: 0.8544\n",
      "Epoch 4/45\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0212 - acc: 0.8590 - val_loss: 0.0216 - val_acc: 0.8545\n",
      "Epoch 5/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0212 - acc: 0.8587 - val_loss: 0.0216 - val_acc: 0.8542\n",
      "Epoch 6/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8589 - val_loss: 0.0216 - val_acc: 0.8544\n",
      "Epoch 7/45\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0212 - acc: 0.8591 - val_loss: 0.0216 - val_acc: 0.8545\n",
      "Epoch 8/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0212 - acc: 0.8588 - val_loss: 0.0216 - val_acc: 0.8546\n",
      "Epoch 9/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0212 - acc: 0.8588 - val_loss: 0.0216 - val_acc: 0.8550\n",
      "Epoch 10/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0212 - acc: 0.8591 - val_loss: 0.0216 - val_acc: 0.8545\n",
      "Epoch 11/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0212 - acc: 0.8590 - val_loss: 0.0216 - val_acc: 0.8548\n",
      "Epoch 12/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0212 - acc: 0.8592 - val_loss: 0.0216 - val_acc: 0.8548\n",
      "Epoch 13/45\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0212 - acc: 0.8594 - val_loss: 0.0216 - val_acc: 0.8541\n",
      "Epoch 14/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8592 - val_loss: 0.0216 - val_acc: 0.8548\n",
      "Epoch 15/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0212 - acc: 0.8591 - val_loss: 0.0216 - val_acc: 0.8551\n",
      "Epoch 16/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0212 - acc: 0.8594 - val_loss: 0.0216 - val_acc: 0.8541\n",
      "Epoch 17/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8593 - val_loss: 0.0216 - val_acc: 0.8545\n",
      "Epoch 18/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8591 - val_loss: 0.0216 - val_acc: 0.8549\n",
      "Epoch 19/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8592 - val_loss: 0.0216 - val_acc: 0.8543\n",
      "Epoch 20/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8593 - val_loss: 0.0216 - val_acc: 0.8552\n",
      "Epoch 21/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8592 - val_loss: 0.0216 - val_acc: 0.8549\n",
      "Epoch 22/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8594 - val_loss: 0.0216 - val_acc: 0.8549\n",
      "Epoch 23/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8594 - val_loss: 0.0216 - val_acc: 0.8549\n",
      "Epoch 24/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0211 - acc: 0.8595 - val_loss: 0.0216 - val_acc: 0.8548\n",
      "Epoch 25/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8594 - val_loss: 0.0216 - val_acc: 0.8551\n",
      "Epoch 26/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8595 - val_loss: 0.0216 - val_acc: 0.8548\n",
      "Epoch 27/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8595 - val_loss: 0.0216 - val_acc: 0.8552\n",
      "Epoch 28/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8595 - val_loss: 0.0216 - val_acc: 0.8551\n",
      "Epoch 29/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8595 - val_loss: 0.0216 - val_acc: 0.8555\n",
      "Epoch 30/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8597 - val_loss: 0.0216 - val_acc: 0.8551\n",
      "Epoch 31/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0211 - acc: 0.8595 - val_loss: 0.0216 - val_acc: 0.8550\n",
      "Epoch 32/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8597 - val_loss: 0.0216 - val_acc: 0.8553\n",
      "Epoch 33/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8596 - val_loss: 0.0216 - val_acc: 0.8549\n",
      "Epoch 34/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8597 - val_loss: 0.0215 - val_acc: 0.8551\n",
      "Epoch 35/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8600 - val_loss: 0.0215 - val_acc: 0.8550\n",
      "Epoch 36/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0211 - acc: 0.8598 - val_loss: 0.0215 - val_acc: 0.8551\n",
      "Epoch 37/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8597 - val_loss: 0.0215 - val_acc: 0.8552\n",
      "Epoch 38/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8597 - val_loss: 0.0215 - val_acc: 0.8554\n",
      "Epoch 39/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8598 - val_loss: 0.0215 - val_acc: 0.8553\n",
      "Epoch 40/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8598 - val_loss: 0.0215 - val_acc: 0.8553\n",
      "Epoch 41/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0211 - acc: 0.8601 - val_loss: 0.0215 - val_acc: 0.8554\n",
      "Epoch 42/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8598 - val_loss: 0.0215 - val_acc: 0.8552\n",
      "Epoch 43/45\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0211 - acc: 0.8600 - val_loss: 0.0215 - val_acc: 0.8555\n",
      "Epoch 44/45\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0211 - acc: 0.8598 - val_loss: 0.0215 - val_acc: 0.8553\n",
      "Epoch 45/45\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0211 - acc: 0.8598 - val_loss: 0.0215 - val_acc: 0.8555\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8600 - val_loss: 0.0215 - val_acc: 0.8553\n",
      "Epoch 2/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8599 - val_loss: 0.0215 - val_acc: 0.8551\n",
      "Epoch 3/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8602 - val_loss: 0.0215 - val_acc: 0.8555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8599 - val_loss: 0.0215 - val_acc: 0.8553\n",
      "Epoch 5/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8600 - val_loss: 0.0215 - val_acc: 0.8555\n",
      "Epoch 6/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8599 - val_loss: 0.0215 - val_acc: 0.8555\n",
      "Epoch 7/46\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0210 - acc: 0.8601 - val_loss: 0.0215 - val_acc: 0.8560\n",
      "Epoch 8/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0210 - acc: 0.8601 - val_loss: 0.0215 - val_acc: 0.8555\n",
      "Epoch 9/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8601 - val_loss: 0.0215 - val_acc: 0.8555\n",
      "Epoch 10/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8603 - val_loss: 0.0215 - val_acc: 0.8555\n",
      "Epoch 11/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8601 - val_loss: 0.0215 - val_acc: 0.8556\n",
      "Epoch 12/46\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0210 - acc: 0.8602 - val_loss: 0.0215 - val_acc: 0.8556\n",
      "Epoch 13/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8601 - val_loss: 0.0215 - val_acc: 0.8560\n",
      "Epoch 14/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8604 - val_loss: 0.0215 - val_acc: 0.8558\n",
      "Epoch 15/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8602 - val_loss: 0.0215 - val_acc: 0.8560\n",
      "Epoch 16/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8604 - val_loss: 0.0215 - val_acc: 0.8560\n",
      "Epoch 17/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8602 - val_loss: 0.0215 - val_acc: 0.8558\n",
      "Epoch 18/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8604 - val_loss: 0.0215 - val_acc: 0.8560\n",
      "Epoch 19/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8603 - val_loss: 0.0215 - val_acc: 0.8557\n",
      "Epoch 20/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8604 - val_loss: 0.0215 - val_acc: 0.8557\n",
      "Epoch 21/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8603 - val_loss: 0.0215 - val_acc: 0.8556\n",
      "Epoch 22/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8605 - val_loss: 0.0215 - val_acc: 0.8560\n",
      "Epoch 23/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0210 - acc: 0.8604 - val_loss: 0.0214 - val_acc: 0.8562\n",
      "Epoch 24/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8603 - val_loss: 0.0214 - val_acc: 0.8559\n",
      "Epoch 25/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0210 - acc: 0.8605 - val_loss: 0.0214 - val_acc: 0.8560\n",
      "Epoch 26/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8605 - val_loss: 0.0214 - val_acc: 0.8562\n",
      "Epoch 27/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0210 - acc: 0.8606 - val_loss: 0.0214 - val_acc: 0.8563\n",
      "Epoch 28/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0210 - acc: 0.8605 - val_loss: 0.0214 - val_acc: 0.8562\n",
      "Epoch 29/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0210 - acc: 0.8604 - val_loss: 0.0214 - val_acc: 0.8562\n",
      "Epoch 30/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0210 - acc: 0.8605 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 31/46\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0209 - acc: 0.8606 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 32/46\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0209 - acc: 0.8606 - val_loss: 0.0214 - val_acc: 0.8568\n",
      "Epoch 33/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8607 - val_loss: 0.0214 - val_acc: 0.8560\n",
      "Epoch 34/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8607 - val_loss: 0.0214 - val_acc: 0.8567\n",
      "Epoch 35/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8608 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 36/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8608 - val_loss: 0.0214 - val_acc: 0.8566\n",
      "Epoch 37/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8605 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 38/46\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0209 - acc: 0.8607 - val_loss: 0.0214 - val_acc: 0.8563\n",
      "Epoch 39/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8608 - val_loss: 0.0214 - val_acc: 0.8563\n",
      "Epoch 40/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8611 - val_loss: 0.0214 - val_acc: 0.8563\n",
      "Epoch 41/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8610 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 42/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8607 - val_loss: 0.0214 - val_acc: 0.8563\n",
      "Epoch 43/46\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0209 - acc: 0.8607 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 44/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8608 - val_loss: 0.0214 - val_acc: 0.8561\n",
      "Epoch 45/46\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8608 - val_loss: 0.0214 - val_acc: 0.8560\n",
      "Epoch 46/46\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8611 - val_loss: 0.0214 - val_acc: 0.8563\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8609 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 2/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8608 - val_loss: 0.0214 - val_acc: 0.8561\n",
      "Epoch 3/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8610 - val_loss: 0.0214 - val_acc: 0.8562\n",
      "Epoch 4/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8610 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 5/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8609 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 6/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8609 - val_loss: 0.0214 - val_acc: 0.8557\n",
      "Epoch 7/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8608 - val_loss: 0.0214 - val_acc: 0.8565\n",
      "Epoch 8/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8611 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 9/47\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0209 - acc: 0.8611 - val_loss: 0.0214 - val_acc: 0.8565\n",
      "Epoch 10/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8611 - val_loss: 0.0214 - val_acc: 0.8564\n",
      "Epoch 11/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8612 - val_loss: 0.0214 - val_acc: 0.8567\n",
      "Epoch 12/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0209 - acc: 0.8611 - val_loss: 0.0214 - val_acc: 0.8563\n",
      "Epoch 13/47\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0209 - acc: 0.8611 - val_loss: 0.0213 - val_acc: 0.8560\n",
      "Epoch 14/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0209 - acc: 0.8613 - val_loss: 0.0213 - val_acc: 0.8561\n",
      "Epoch 15/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0208 - acc: 0.8613 - val_loss: 0.0213 - val_acc: 0.8563\n",
      "Epoch 16/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0208 - acc: 0.8613 - val_loss: 0.0213 - val_acc: 0.8563\n",
      "Epoch 17/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8614 - val_loss: 0.0213 - val_acc: 0.8563\n",
      "Epoch 18/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8613 - val_loss: 0.0213 - val_acc: 0.8570\n",
      "Epoch 19/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8610 - val_loss: 0.0213 - val_acc: 0.8562\n",
      "Epoch 20/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8612 - val_loss: 0.0213 - val_acc: 0.8563\n",
      "Epoch 21/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8615 - val_loss: 0.0213 - val_acc: 0.8565\n",
      "Epoch 22/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8613 - val_loss: 0.0213 - val_acc: 0.8564\n",
      "Epoch 23/47\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0208 - acc: 0.8614 - val_loss: 0.0213 - val_acc: 0.8565\n",
      "Epoch 24/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8613 - val_loss: 0.0213 - val_acc: 0.8568\n",
      "Epoch 25/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0208 - acc: 0.8615 - val_loss: 0.0213 - val_acc: 0.8562\n",
      "Epoch 26/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0208 - acc: 0.8614 - val_loss: 0.0213 - val_acc: 0.8567\n",
      "Epoch 27/47\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0208 - acc: 0.8615 - val_loss: 0.0213 - val_acc: 0.8566\n",
      "Epoch 28/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8613 - val_loss: 0.0213 - val_acc: 0.8566\n",
      "Epoch 29/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8615 - val_loss: 0.0213 - val_acc: 0.8566\n",
      "Epoch 30/47\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0208 - acc: 0.8616 - val_loss: 0.0213 - val_acc: 0.8566\n",
      "Epoch 31/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8615 - val_loss: 0.0213 - val_acc: 0.8566\n",
      "Epoch 32/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8616 - val_loss: 0.0213 - val_acc: 0.8564\n",
      "Epoch 33/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8616 - val_loss: 0.0213 - val_acc: 0.8564\n",
      "Epoch 34/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0208 - acc: 0.8618 - val_loss: 0.0213 - val_acc: 0.8569\n",
      "Epoch 35/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0208 - acc: 0.8614 - val_loss: 0.0213 - val_acc: 0.8569\n",
      "Epoch 36/47\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0208 - acc: 0.8616 - val_loss: 0.0213 - val_acc: 0.8568\n",
      "Epoch 37/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8617 - val_loss: 0.0213 - val_acc: 0.8567\n",
      "Epoch 38/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8620 - val_loss: 0.0213 - val_acc: 0.8568\n",
      "Epoch 39/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8614 - val_loss: 0.0213 - val_acc: 0.8565\n",
      "Epoch 40/47\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0208 - acc: 0.8620 - val_loss: 0.0213 - val_acc: 0.8567\n",
      "Epoch 41/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8617 - val_loss: 0.0213 - val_acc: 0.8566\n",
      "Epoch 42/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8618 - val_loss: 0.0213 - val_acc: 0.8567\n",
      "Epoch 43/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8618 - val_loss: 0.0213 - val_acc: 0.8568\n",
      "Epoch 44/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0208 - acc: 0.8616 - val_loss: 0.0213 - val_acc: 0.8574\n",
      "Epoch 45/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0208 - acc: 0.8619 - val_loss: 0.0213 - val_acc: 0.8572\n",
      "Epoch 46/47\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0208 - acc: 0.8619 - val_loss: 0.0213 - val_acc: 0.8568\n",
      "Epoch 47/47\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8618 - val_loss: 0.0213 - val_acc: 0.8571\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/48\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0207 - acc: 0.8617 - val_loss: 0.0213 - val_acc: 0.8571\n",
      "Epoch 2/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8619 - val_loss: 0.0212 - val_acc: 0.8569\n",
      "Epoch 3/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8619 - val_loss: 0.0212 - val_acc: 0.8568\n",
      "Epoch 4/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8618 - val_loss: 0.0212 - val_acc: 0.8565\n",
      "Epoch 5/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8617 - val_loss: 0.0212 - val_acc: 0.8570\n",
      "Epoch 6/48\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0207 - acc: 0.8619 - val_loss: 0.0212 - val_acc: 0.8575\n",
      "Epoch 7/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8618 - val_loss: 0.0212 - val_acc: 0.8567\n",
      "Epoch 8/48\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0207 - acc: 0.8619 - val_loss: 0.0212 - val_acc: 0.8568\n",
      "Epoch 9/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.8571\n",
      "Epoch 10/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8621 - val_loss: 0.0212 - val_acc: 0.8573\n",
      "Epoch 11/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8620 - val_loss: 0.0212 - val_acc: 0.8570\n",
      "Epoch 12/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8623 - val_loss: 0.0212 - val_acc: 0.8568\n",
      "Epoch 13/48\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0207 - acc: 0.8621 - val_loss: 0.0212 - val_acc: 0.8572\n",
      "Epoch 14/48\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.8571\n",
      "Epoch 15/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8621 - val_loss: 0.0212 - val_acc: 0.8574\n",
      "Epoch 16/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.8572\n",
      "Epoch 17/48\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.85760s - loss: 0.0207 - acc: 0.862\n",
      "Epoch 18/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.8574\n",
      "Epoch 19/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.8572\n",
      "Epoch 20/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.8572\n",
      "Epoch 21/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8623 - val_loss: 0.0212 - val_acc: 0.8576\n",
      "Epoch 22/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.8573\n",
      "Epoch 23/48\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0207 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8577\n",
      "Epoch 24/48\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0207 - acc: 0.8625 - val_loss: 0.0212 - val_acc: 0.8571\n",
      "Epoch 25/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8625 - val_loss: 0.0212 - val_acc: 0.8576\n",
      "Epoch 26/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8622 - val_loss: 0.0212 - val_acc: 0.8575\n",
      "Epoch 27/48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8575\n",
      "Epoch 28/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8574\n",
      "Epoch 29/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8625 - val_loss: 0.0212 - val_acc: 0.8574\n",
      "Epoch 30/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0207 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8572\n",
      "Epoch 31/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0207 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8575\n",
      "Epoch 32/48\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0207 - acc: 0.862 - 1s 23us/sample - loss: 0.0206 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8574\n",
      "Epoch 33/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8625 - val_loss: 0.0212 - val_acc: 0.8573\n",
      "Epoch 34/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8625 - val_loss: 0.0212 - val_acc: 0.8575\n",
      "Epoch 35/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8625 - val_loss: 0.0212 - val_acc: 0.8577\n",
      "Epoch 36/48\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0206 - acc: 0.862 - 1s 22us/sample - loss: 0.0206 - acc: 0.8628 - val_loss: 0.0212 - val_acc: 0.8576\n",
      "Epoch 37/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8575\n",
      "Epoch 38/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8577\n",
      "Epoch 39/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8628 - val_loss: 0.0212 - val_acc: 0.8575\n",
      "Epoch 40/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8628 - val_loss: 0.0212 - val_acc: 0.8577\n",
      "Epoch 41/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8628 - val_loss: 0.0212 - val_acc: 0.8575\n",
      "Epoch 42/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8626 - val_loss: 0.0212 - val_acc: 0.8577\n",
      "Epoch 43/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8628 - val_loss: 0.0212 - val_acc: 0.8578\n",
      "Epoch 44/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8628 - val_loss: 0.0211 - val_acc: 0.8578\n",
      "Epoch 45/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8628 - val_loss: 0.0211 - val_acc: 0.8574\n",
      "Epoch 46/48\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8629 - val_loss: 0.0212 - val_acc: 0.8576\n",
      "Epoch 47/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8630 - val_loss: 0.0211 - val_acc: 0.8577\n",
      "Epoch 48/48\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8626 - val_loss: 0.0211 - val_acc: 0.8576\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8628 - val_loss: 0.0211 - val_acc: 0.8574\n",
      "Epoch 2/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8629 - val_loss: 0.0211 - val_acc: 0.8579\n",
      "Epoch 3/49\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0206 - acc: 0.8629 - val_loss: 0.0211 - val_acc: 0.8579\n",
      "Epoch 4/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8630 - val_loss: 0.0211 - val_acc: 0.8578\n",
      "Epoch 5/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8631 - val_loss: 0.0211 - val_acc: 0.8580\n",
      "Epoch 6/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8631 - val_loss: 0.0211 - val_acc: 0.8579\n",
      "Epoch 7/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8630 - val_loss: 0.0211 - val_acc: 0.8578\n",
      "Epoch 8/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8629 - val_loss: 0.0211 - val_acc: 0.8578\n",
      "Epoch 9/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8630 - val_loss: 0.0211 - val_acc: 0.8575\n",
      "Epoch 10/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8629 - val_loss: 0.0211 - val_acc: 0.8576\n",
      "Epoch 11/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0206 - acc: 0.8631 - val_loss: 0.0211 - val_acc: 0.8579\n",
      "Epoch 12/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8630 - val_loss: 0.0211 - val_acc: 0.8579\n",
      "Epoch 13/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8631 - val_loss: 0.0211 - val_acc: 0.8580\n",
      "Epoch 14/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8630 - val_loss: 0.0211 - val_acc: 0.8579\n",
      "Epoch 15/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8631 - val_loss: 0.0211 - val_acc: 0.8580\n",
      "Epoch 16/49\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0206 - acc: 0.8630 - val_loss: 0.0211 - val_acc: 0.8578\n",
      "Epoch 17/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0206 - acc: 0.8631 - val_loss: 0.0211 - val_acc: 0.8580\n",
      "Epoch 18/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8632 - val_loss: 0.0211 - val_acc: 0.8583\n",
      "Epoch 19/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8635 - val_loss: 0.0211 - val_acc: 0.8580\n",
      "Epoch 20/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8631 - val_loss: 0.0211 - val_acc: 0.8584\n",
      "Epoch 21/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8633 - val_loss: 0.0211 - val_acc: 0.8584\n",
      "Epoch 22/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8635 - val_loss: 0.0211 - val_acc: 0.8582\n",
      "Epoch 23/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8632 - val_loss: 0.0211 - val_acc: 0.8583\n",
      "Epoch 24/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8632 - val_loss: 0.0211 - val_acc: 0.8581\n",
      "Epoch 25/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8633 - val_loss: 0.0211 - val_acc: 0.8585\n",
      "Epoch 26/49\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0205 - acc: 0.8633 - val_loss: 0.0211 - val_acc: 0.8584\n",
      "Epoch 27/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8633 - val_loss: 0.0211 - val_acc: 0.8581\n",
      "Epoch 28/49\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0205 - acc: 0.8634 - val_loss: 0.0211 - val_acc: 0.8585\n",
      "Epoch 29/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8633 - val_loss: 0.0211 - val_acc: 0.8584\n",
      "Epoch 30/49\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0205 - acc: 0.8632 - val_loss: 0.0211 - val_acc: 0.8584\n",
      "Epoch 31/49\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0205 - acc: 0.8634 - val_loss: 0.0211 - val_acc: 0.8584\n",
      "Epoch 32/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8634 - val_loss: 0.0211 - val_acc: 0.8585\n",
      "Epoch 33/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8633 - val_loss: 0.0211 - val_acc: 0.8584\n",
      "Epoch 34/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8636 - val_loss: 0.0211 - val_acc: 0.8584\n",
      "Epoch 35/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8637 - val_loss: 0.0210 - val_acc: 0.8585\n",
      "Epoch 36/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8636 - val_loss: 0.0210 - val_acc: 0.8586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8636 - val_loss: 0.0210 - val_acc: 0.8583\n",
      "Epoch 38/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8636 - val_loss: 0.0210 - val_acc: 0.8583\n",
      "Epoch 39/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8637 - val_loss: 0.0210 - val_acc: 0.8587\n",
      "Epoch 40/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8636 - val_loss: 0.0210 - val_acc: 0.8587\n",
      "Epoch 41/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8637 - val_loss: 0.0210 - val_acc: 0.8586\n",
      "Epoch 42/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8637 - val_loss: 0.0210 - val_acc: 0.8585\n",
      "Epoch 43/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8637 - val_loss: 0.0210 - val_acc: 0.8588\n",
      "Epoch 44/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8635 - val_loss: 0.0210 - val_acc: 0.8587\n",
      "Epoch 45/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8636 - val_loss: 0.0210 - val_acc: 0.8587\n",
      "Epoch 46/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8638 - val_loss: 0.0210 - val_acc: 0.8583\n",
      "Epoch 47/49\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0205 - acc: 0.8639 - val_loss: 0.0210 - val_acc: 0.8585\n",
      "Epoch 48/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8638 - val_loss: 0.0210 - val_acc: 0.8586\n",
      "Epoch 49/49\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0205 - acc: 0.8637 - val_loss: 0.0210 - val_acc: 0.8586\n"
     ]
    }
   ],
   "source": [
    "# обучим модель на 49 эпохах\n",
    "val_accuracy = model_regression.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    epochs=49,\n",
    "    batch_size=500,\n",
    "    verbose = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим датафрейм для анализа получившихся результатов\n",
    "valid = pd.DataFrame({'epochs':range(1,50),'val_accuracy':val_accuracy.history['val_acc']}).sort_values('val_accuracy',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.303950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.485450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.560840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.629783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.659071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.674537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.699144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.724310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.745173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.761500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.774785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.785093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.792400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.799856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.805588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.809906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.813200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.816790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.820319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.823136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.825974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.827629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.829336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.831685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.832726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.834593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.835779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.837470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0.839248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>0.840994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>0.842530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0.844743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0.845619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>0.847441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0.848803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>0.849510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>0.849808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0.850666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>0.851843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0.852777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>0.853709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>0.854889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0.855991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0.856538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>0.857346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>0.858229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  val_accuracy\n",
       "0        1      0.171600\n",
       "1        2      0.303950\n",
       "2        3      0.388200\n",
       "3        4      0.485450\n",
       "4        5      0.560840\n",
       "5        6      0.629783\n",
       "6        7      0.659071\n",
       "7        8      0.674537\n",
       "8        9      0.699144\n",
       "9       10      0.724310\n",
       "10      11      0.745173\n",
       "11      12      0.761500\n",
       "12      13      0.774785\n",
       "13      14      0.785093\n",
       "14      15      0.792400\n",
       "15      16      0.799856\n",
       "16      17      0.805588\n",
       "17      18      0.809906\n",
       "18      19      0.813200\n",
       "19      20      0.816790\n",
       "20      21      0.820319\n",
       "21      22      0.823136\n",
       "22      23      0.825974\n",
       "23      24      0.827629\n",
       "24      25      0.829336\n",
       "25      26      0.831685\n",
       "26      27      0.832726\n",
       "27      28      0.834593\n",
       "28      29      0.835779\n",
       "29      30      0.837470\n",
       "30      31      0.839248\n",
       "31      32      0.840994\n",
       "32      33      0.842530\n",
       "33      34      0.844015\n",
       "34      35      0.844743\n",
       "35      36      0.845619\n",
       "36      37      0.847441\n",
       "37      38      0.848803\n",
       "38      39      0.849510\n",
       "39      40      0.849808\n",
       "40      41      0.850666\n",
       "41      42      0.851843\n",
       "42      43      0.852777\n",
       "43      44      0.853709\n",
       "44      45      0.854889\n",
       "45      46      0.855991\n",
       "46      47      0.856538\n",
       "47      48      0.857346\n",
       "48      49      0.858229"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заметим, что наилучшее качество достигается при 49 эпохах\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# визуализируем результаты\n",
    "plt.plot(range(1,50),valid['val_accuracy'])\n",
    "plt.xlabel('Количество эпох',fontdict={'fontsize':18})\n",
    "plt.ylabel('Качество на валидационной выборке',fontdict={'fontsize':18})\n",
    "plt.savefig('val_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 50us/sample - loss: 0.0209 - acc: 0.8599\n"
     ]
    }
   ],
   "source": [
    "# РЕЗУЛЬТАТ НА ТЕСТОВОЙ ВЫБОРКЕ\n",
    "accuracy_regression =  model_regression.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### ПОЛНОСВЯЗНАЯ НЕЙРОННАЯ СЕТЬ #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# СОЗДАДИМ НЕЙРОННУЮ СЕТЬ С ПЯТЬЮ СЛОЯМИ\n",
    "model_connected = tf.keras.models.Sequential()\n",
    "model_connected.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)))\n",
    "model_connected.add(tf.keras.layers.Dropout(0.1))\n",
    "model_connected.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model_connected.add(tf.keras.layers.Dropout(0.1))\n",
    "model_connected.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем: будем минимизировать КРОСС-ЭНТРОПИЮ, оптимизировать по АДАМ и оценивать качетсво модели на метрике accuracy\n",
    "model_connected.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer=tf.keras.optimizers.Adam(),\n",
    "metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/49\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.5951 - acc: 0.7885 - val_loss: 0.4156 - val_acc: 0.8529\n",
      "Epoch 2/49\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3922 - acc: 0.8588 - val_loss: 0.3506 - val_acc: 0.8764\n",
      "Epoch 3/49\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3472 - acc: 0.8742 - val_loss: 0.3342 - val_acc: 0.8770\n",
      "Epoch 4/49\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3214 - acc: 0.8825 - val_loss: 0.3310 - val_acc: 0.8806\n",
      "Epoch 5/49\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.3011 - acc: 0.8880 - val_loss: 0.3030 - val_acc: 0.8864\n",
      "Epoch 6/49\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2855 - acc: 0.8938 - val_loss: 0.3137 - val_acc: 0.8833\n",
      "Epoch 7/49\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2722 - acc: 0.8995 - val_loss: 0.2944 - val_acc: 0.8899\n",
      "Epoch 8/49\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2624 - acc: 0.9030 - val_loss: 0.2759 - val_acc: 0.8992\n",
      "Epoch 9/49\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2518 - acc: 0.9058 - val_loss: 0.2999 - val_acc: 0.8915\n",
      "Epoch 10/49\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2406 - acc: 0.9091 - val_loss: 0.2837 - val_acc: 0.8967\n",
      "Epoch 11/49\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2309 - acc: 0.9132 - val_loss: 0.2857 - val_acc: 0.8926\n",
      "Epoch 12/49\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2301 - acc: 0.9139 - val_loss: 0.2750 - val_acc: 0.9021\n",
      "Epoch 13/49\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2154 - acc: 0.9197 - val_loss: 0.2738 - val_acc: 0.8999\n",
      "Epoch 14/49\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2084 - acc: 0.9220 - val_loss: 0.2850 - val_acc: 0.8990\n",
      "Epoch 15/49\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2053 - acc: 0.9215 - val_loss: 0.2909 - val_acc: 0.8965\n",
      "Epoch 16/49\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2013 - acc: 0.9246 - val_loss: 0.2800 - val_acc: 0.8973\n",
      "Epoch 17/49\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.1920 - acc: 0.9273 - val_loss: 0.2876 - val_acc: 0.8994\n",
      "Epoch 18/49\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1848 - acc: 0.9298 - val_loss: 0.3042 - val_acc: 0.8954\n",
      "Epoch 19/49\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1873 - acc: 0.9287 - val_loss: 0.2868 - val_acc: 0.8991\n",
      "Epoch 20/49\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1790 - acc: 0.9327 - val_loss: 0.2911 - val_acc: 0.8993\n",
      "Epoch 21/49\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.1780 - acc: 0.9335 - val_loss: 0.2909 - val_acc: 0.8990\n",
      "Epoch 22/49\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1690 - acc: 0.9361 - val_loss: 0.2826 - val_acc: 0.9036\n",
      "Epoch 23/49\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1615 - acc: 0.9385 - val_loss: 0.2969 - val_acc: 0.8998\n",
      "Epoch 24/49\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1609 - acc: 0.9383 - val_loss: 0.2930 - val_acc: 0.9005\n",
      "Epoch 25/49\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1578 - acc: 0.9402 - val_loss: 0.2910 - val_acc: 0.9059\n",
      "Epoch 26/49\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1566 - acc: 0.9406 - val_loss: 0.3010 - val_acc: 0.9041\n",
      "Epoch 27/49\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1506 - acc: 0.9431 - val_loss: 0.3043 - val_acc: 0.9001\n",
      "Epoch 28/49\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1465 - acc: 0.9442 - val_loss: 0.3077 - val_acc: 0.8977\n",
      "Epoch 29/49\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1424 - acc: 0.9463 - val_loss: 0.3077 - val_acc: 0.9032\n",
      "Epoch 30/49\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1350 - acc: 0.9492 - val_loss: 0.3047 - val_acc: 0.9008\n",
      "Epoch 31/49\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1370 - acc: 0.9485 - val_loss: 0.3286 - val_acc: 0.9007\n",
      "Epoch 32/49\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1284 - acc: 0.9507 - val_loss: 0.3126 - val_acc: 0.9020\n",
      "Epoch 33/49\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1304 - acc: 0.9511 - val_loss: 0.3171 - val_acc: 0.9032\n",
      "Epoch 34/49\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1283 - acc: 0.9509 - val_loss: 0.3314 - val_acc: 0.9019\n",
      "Epoch 35/49\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.1260 - acc: 0.9519 - val_loss: 0.3381 - val_acc: 0.9013\n",
      "Epoch 36/49\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1248 - acc: 0.9521 - val_loss: 0.3297 - val_acc: 0.9003\n",
      "Epoch 37/49\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1222 - acc: 0.9538 - val_loss: 0.3339 - val_acc: 0.9064\n",
      "Epoch 38/49\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1142 - acc: 0.9561 - val_loss: 0.3232 - val_acc: 0.9049\n",
      "Epoch 39/49\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1135 - acc: 0.9569 - val_loss: 0.3320 - val_acc: 0.9048\n",
      "Epoch 40/49\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1060 - acc: 0.9599 - val_loss: 0.3567 - val_acc: 0.8992\n",
      "Epoch 41/49\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1091 - acc: 0.9574 - val_loss: 0.3337 - val_acc: 0.9038\n",
      "Epoch 42/49\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1095 - acc: 0.9572 - val_loss: 0.3558 - val_acc: 0.8974\n",
      "Epoch 43/49\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1024 - acc: 0.9613 - val_loss: 0.3401 - val_acc: 0.9058\n",
      "Epoch 44/49\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1047 - acc: 0.9604 - val_loss: 0.3486 - val_acc: 0.9053\n",
      "Epoch 45/49\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.1015 - acc: 0.9614 - val_loss: 0.3558 - val_acc: 0.8991\n",
      "Epoch 46/49\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0948 - acc: 0.9644 - val_loss: 0.3666 - val_acc: 0.9034\n",
      "Epoch 47/49\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0926 - acc: 0.9646 - val_loss: 0.3634 - val_acc: 0.9023\n",
      "Epoch 48/49\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.0936 - acc: 0.9645 - val_loss: 0.3715 - val_acc: 0.9053\n",
      "Epoch 49/49\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0913 - acc: 0.9649 - val_loss: 0.3583 - val_acc: 0.9075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24832d550c8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ОБУЧИМ МОДЕЛЬ ТАУКЖЕ НА 49 ЭПОХАХ\n",
    "model_connected.fit(\n",
    "x_train, y_train,\n",
    "validation_data=(x_valid, y_valid),\n",
    "epochs=49,\n",
    "batch_size=500,\n",
    "verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 25s 2ms/sample - loss: 0.3583 - acc: 0.9075\n"
     ]
    }
   ],
   "source": [
    "# РЕЗУЛЬТАТ НА ТЕСТОВОЙ ВЫБОРКЕ\n",
    "accuracy_connected = model_connected.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПОЛНОСВЯЗНАЯ НЕЙРОННАЯ СЕТЬ РАБОТАЕТ ЛУЧШЕ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ, ТАК КАК ДАННАЯ СЕТЬ ОСНОВАНА НА БОЛЕЕ СЛОЖНОЙ АРХИТЕКТУРЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### СВЕРТОЧНАЯ НЕЙРОННАЯ СЕТЬ #########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПРЕОБРАЗУЕМ РАЗМЕРНОСТЬ ТЕСТОВОЙ И ТРЕНИРОВОЧНОЙ ВЫБОРОК\n",
    "x_train = np.array(x_train).reshape(60000,28,28,1)\n",
    "x_test = np.array(x_test).reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# СОЗДАДИМ НЕЙРОННУЮ СЕТЬ С СЕМЬЮ СКРЫТЫМИ СЛОЯМИ\n",
    "model_convolutional = tf.keras.models.Sequential()\n",
    "model_convolutional.add((tf.keras.layers.Convolution2D(32,(3,3),activation='relu',input_shape=(28,28,1))))\n",
    "model_convolutional.add((tf.keras.layers.MaxPooling2D(pool_size=(2,2))))\n",
    "model_convolutional.add((tf.keras.layers.Convolution2D(64,(3,3),activation='relu')))\n",
    "model_convolutional.add((tf.keras.layers.MaxPooling2D(pool_size=(2,2))))\n",
    "model_convolutional.add(tf.keras.layers.Flatten())\n",
    "model_convolutional.add(tf.keras.layers.Dense(64,activation = 'relu'))\n",
    "model_convolutional.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# КОМПИЛЯЦИЯ АНАЛОГИЧНАЯ ПОЛНОСВЯЗНОЙ НЕЙРОННОЙ СЕТИ\n",
    "model_convolutional.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer=tf.keras.optimizers.Adam(),\n",
    "metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.6964 - acc: 0.7581 - val_loss: 0.4414 - val_acc: 0.8413\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4136 - acc: 0.8529 - val_loss: 0.3718 - val_acc: 0.8711\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.3676 - acc: 0.8694 - val_loss: 0.3553 - val_acc: 0.8753\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.3348 - acc: 0.8818 - val_loss: 0.3303 - val_acc: 0.8790\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3115 - acc: 0.8899 - val_loss: 0.3173 - val_acc: 0.8881\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2959 - acc: 0.8946 - val_loss: 0.2947 - val_acc: 0.8941\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2821 - acc: 0.8991 - val_loss: 0.2792 - val_acc: 0.9015\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2717 - acc: 0.9031 - val_loss: 0.2751 - val_acc: 0.9025\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2581 - acc: 0.9075 - val_loss: 0.2764 - val_acc: 0.9025\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2482 - acc: 0.9103 - val_loss: 0.2830 - val_acc: 0.8956\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2381 - acc: 0.9146 - val_loss: 0.2573 - val_acc: 0.9084\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2290 - acc: 0.9181 - val_loss: 0.2559 - val_acc: 0.9075\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2213 - acc: 0.9198 - val_loss: 0.2501 - val_acc: 0.9122\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2128 - acc: 0.9230 - val_loss: 0.2509 - val_acc: 0.9100\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2040 - acc: 0.9263 - val_loss: 0.2413 - val_acc: 0.9145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x246cb4a7ac8>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ОБУЧИМ МОДЕЛЬ НА 15 ЭПОХАХ \n",
    "model_convolutional.fit(\n",
    "x_train, y_train,\n",
    "validation_data=(x_valid, y_valid),\n",
    "epochs=15,\n",
    "batch_size=300,\n",
    "verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 599us/sample - loss: 0.2413 - acc: 0.9145\n"
     ]
    }
   ],
   "source": [
    "# РЕЗУЛЬТАТ НА ТЕСТОВЫХ ДАННЫХ\n",
    "accuracy_convolutional = model_convolutional.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# СОЗДАДИМ НЕЙРОННУЮ СЕТЬ С СЕМЬЮ СКРЫТЫМИ СЛОЯМИ, ДОБАВИВ ПРИ ЭТОМ Batch Normalization ПОСЛЕ СЛОЯ ПОЛНОСВЯЗНОЙ НЕЙРОННОЙ СЕТИ\n",
    "model_convolutional = tf.keras.models.Sequential()\n",
    "model_convolutional.add((tf.keras.layers.Convolution2D(32,(3,3),activation='relu',input_shape=(28,28,1))))\n",
    "model_convolutional.add((tf.keras.layers.MaxPooling2D(pool_size=(2,2))))\n",
    "model_convolutional.add((tf.keras.layers.Convolution2D(64,(3,3),activation='relu')))\n",
    "model_convolutional.add((tf.keras.layers.MaxPooling2D(pool_size=(2,2))))\n",
    "model_convolutional.add(tf.keras.layers.Flatten())\n",
    "model_convolutional.add(tf.keras.layers.Dense(64,activation = 'relu'))\n",
    "model_convolutional.add(tf.keras.layers.BatchNormalization())\n",
    "model_convolutional.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_convolutional.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer=tf.keras.optimizers.Adam(),\n",
    "metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.4841 - acc: 0.8326 - val_loss: 1.0848 - val_acc: 0.8399\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3046 - acc: 0.8927 - val_loss: 0.4184 - val_acc: 0.8910\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2643 - acc: 0.9045 - val_loss: 0.3487 - val_acc: 0.8709\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2384 - acc: 0.9146 - val_loss: 0.3148 - val_acc: 0.8891\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2154 - acc: 0.9222 - val_loss: 0.2974 - val_acc: 0.8925\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1999 - acc: 0.9285 - val_loss: 0.2690 - val_acc: 0.9020\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1839 - acc: 0.9320 - val_loss: 0.2761 - val_acc: 0.9049\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1723 - acc: 0.9379 - val_loss: 0.2908 - val_acc: 0.9046\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.1605 - acc: 0.9410 - val_loss: 0.2893 - val_acc: 0.9030\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1468 - acc: 0.9460 - val_loss: 0.2636 - val_acc: 0.9101\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1354 - acc: 0.9517 - val_loss: 0.3008 - val_acc: 0.9029\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1275 - acc: 0.9538 - val_loss: 0.2694 - val_acc: 0.9114\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1193 - acc: 0.9561 - val_loss: 0.3305 - val_acc: 0.8969\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1099 - acc: 0.9596 - val_loss: 0.2874 - val_acc: 0.9130\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1015 - acc: 0.9629 - val_loss: 0.3264 - val_acc: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x246aaa4f908>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_convolutional.fit(\n",
    "x_train, y_train,\n",
    "validation_data=(x_valid, y_valid),\n",
    "epochs=15,\n",
    "batch_size=300,\n",
    "verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 654us/sample - loss: 0.3264 - acc: 0.9026\n"
     ]
    }
   ],
   "source": [
    "accuracy_convolutional_1 = model_convolutional.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПО СРАВНЕНИЮ С ПОЛНОСВЯЗНОЙ НЕЙРОННОЙ СЕТЬЮ СВЕРТОЧНАЯ ДАЛА ЛУЧШИЙ РЕЗУЛЬТАТ, ЭТО СВЯЗАНО, В ПЕРВУЮ ОЧЕРЕДЬ,С ДОБАВЛЕНИЕМ \n",
    "# СВЕРТОЧНЫХ СЛОЕВ И СЛОЕВ СУБ-ДИСКРЕТИЗАЦИИ\n",
    "# ДОБАВЛЕНИЕ Batch Normalization НЕ ПРИВЕЛО К УВЕЛЕЧЕНИЮ КАЧЕСТВА МОДЕЛИ, А НАОБОРОТ СНИЗИЛО ЕГО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### ПОДВЕДЕНИЕ ИТОГОВ #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.DataFrame({'accuracy':[accuracy_regression,accuracy_connected,accuracy_convolutional]},index = ['регрессия',\n",
    "                                                                                                           'полносвязная_нс',\n",
    "                                                                                                          'сверточная_нс'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>регрессия</th>\n",
       "      <td>0.8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>полносвязная_нс</th>\n",
       "      <td>0.9075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>сверточная_нс</th>\n",
       "      <td>0.9127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy\n",
       "регрессия          0.8599\n",
       "полносвязная_нс    0.9075\n",
       "сверточная_нс      0.9127"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "age = total.sort_values('accuracy').plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ТАКИМ ОБРАЗОМ, МАКСИМАЛЬНОЕ КАЧЕСТВО НА ТЕСТОВОЙ ВЫБОРКЕ ПОКАЗАЛА СВЕРТОЧНАЯ НЕЙРОННАЯ СЕТЬ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
